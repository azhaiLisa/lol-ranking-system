{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 9.995002498750624,
  "eval_steps": 500,
  "global_step": 100000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.009995002498750625,
      "grad_norm": 0.006324106361716986,
      "learning_rate": 0.000499765,
      "loss": 0.3656,
      "step": 100
    },
    {
      "epoch": 0.01999000499750125,
      "grad_norm": 0.0033730724826455116,
      "learning_rate": 0.000499265,
      "loss": 0.0002,
      "step": 200
    },
    {
      "epoch": 0.029985007496251874,
      "grad_norm": 0.0020565090235322714,
      "learning_rate": 0.000498765,
      "loss": 0.0001,
      "step": 300
    },
    {
      "epoch": 0.0399800099950025,
      "grad_norm": 0.001383015071041882,
      "learning_rate": 0.000498265,
      "loss": 0.0001,
      "step": 400
    },
    {
      "epoch": 0.04997501249375312,
      "grad_norm": 0.0009847680339589715,
      "learning_rate": 0.0004977650000000001,
      "loss": 0.0001,
      "step": 500
    },
    {
      "epoch": 0.05997001499250375,
      "grad_norm": 0.0007260892307385802,
      "learning_rate": 0.000497265,
      "loss": 0.0,
      "step": 600
    },
    {
      "epoch": 0.06996501749125437,
      "grad_norm": 0.0005586805636994541,
      "learning_rate": 0.000496765,
      "loss": 0.0,
      "step": 700
    },
    {
      "epoch": 0.079960019990005,
      "grad_norm": 0.00043840412399731576,
      "learning_rate": 0.0004962650000000001,
      "loss": 0.0,
      "step": 800
    },
    {
      "epoch": 0.08995502248875563,
      "grad_norm": 0.00035247282357886434,
      "learning_rate": 0.000495765,
      "loss": 0.0,
      "step": 900
    },
    {
      "epoch": 0.09995002498750624,
      "grad_norm": 0.0002899002283811569,
      "learning_rate": 0.000495265,
      "loss": 0.0,
      "step": 1000
    },
    {
      "epoch": 0.10994502748625687,
      "grad_norm": 0.00024162171757780015,
      "learning_rate": 0.000494765,
      "loss": 0.0,
      "step": 1100
    },
    {
      "epoch": 0.1199400299850075,
      "grad_norm": 0.00020268380467314273,
      "learning_rate": 0.000494265,
      "loss": 0.0,
      "step": 1200
    },
    {
      "epoch": 0.12993503248375812,
      "grad_norm": 0.0001714366371743381,
      "learning_rate": 0.0004937650000000001,
      "loss": 0.0,
      "step": 1300
    },
    {
      "epoch": 0.13993003498250875,
      "grad_norm": 0.00014742313942406327,
      "learning_rate": 0.000493265,
      "loss": 0.0,
      "step": 1400
    },
    {
      "epoch": 0.14992503748125938,
      "grad_norm": 0.00012540581519715488,
      "learning_rate": 0.000492765,
      "loss": 0.0,
      "step": 1500
    },
    {
      "epoch": 0.15992003998001,
      "grad_norm": 0.00010727043991209939,
      "learning_rate": 0.000492265,
      "loss": 0.0,
      "step": 1600
    },
    {
      "epoch": 0.16991504247876063,
      "grad_norm": 9.349862375529483e-05,
      "learning_rate": 0.000491765,
      "loss": 0.0,
      "step": 1700
    },
    {
      "epoch": 0.17991004497751126,
      "grad_norm": 8.01787682576105e-05,
      "learning_rate": 0.0004912650000000001,
      "loss": 0.0,
      "step": 1800
    },
    {
      "epoch": 0.18990504747626186,
      "grad_norm": 7.251409260788932e-05,
      "learning_rate": 0.000490765,
      "loss": 0.0,
      "step": 1900
    },
    {
      "epoch": 0.19990004997501248,
      "grad_norm": 6.296423816820607e-05,
      "learning_rate": 0.000490265,
      "loss": 0.0,
      "step": 2000
    },
    {
      "epoch": 0.2098950524737631,
      "grad_norm": 5.4728356190025806e-05,
      "learning_rate": 0.000489765,
      "loss": 0.0,
      "step": 2100
    },
    {
      "epoch": 0.21989005497251374,
      "grad_norm": 4.712034569820389e-05,
      "learning_rate": 0.000489265,
      "loss": 0.0,
      "step": 2200
    },
    {
      "epoch": 0.22988505747126436,
      "grad_norm": 4.213870852254331e-05,
      "learning_rate": 0.0004887650000000001,
      "loss": 0.0,
      "step": 2300
    },
    {
      "epoch": 0.239880059970015,
      "grad_norm": 3.6374527553562075e-05,
      "learning_rate": 0.000488265,
      "loss": 0.0,
      "step": 2400
    },
    {
      "epoch": 0.24987506246876562,
      "grad_norm": 3.295365968369879e-05,
      "learning_rate": 0.00048776500000000003,
      "loss": 0.0,
      "step": 2500
    },
    {
      "epoch": 0.25987006496751625,
      "grad_norm": 2.7482781661092304e-05,
      "learning_rate": 0.000487265,
      "loss": 0.0,
      "step": 2600
    },
    {
      "epoch": 0.2698650674662669,
      "grad_norm": 2.478306123521179e-05,
      "learning_rate": 0.000486765,
      "loss": 0.0,
      "step": 2700
    },
    {
      "epoch": 0.2798600699650175,
      "grad_norm": 2.2214917407836765e-05,
      "learning_rate": 0.000486265,
      "loss": 0.0,
      "step": 2800
    },
    {
      "epoch": 0.2898550724637681,
      "grad_norm": 2.0929957827320322e-05,
      "learning_rate": 0.00048576500000000004,
      "loss": 0.0,
      "step": 2900
    },
    {
      "epoch": 0.29985007496251875,
      "grad_norm": 1.615549081179779e-05,
      "learning_rate": 0.000485265,
      "loss": 0.0,
      "step": 3000
    },
    {
      "epoch": 0.3098450774612694,
      "grad_norm": 1.5745259588584304e-05,
      "learning_rate": 0.000484765,
      "loss": 0.0,
      "step": 3100
    },
    {
      "epoch": 0.31984007996002,
      "grad_norm": 1.5752004401292652e-05,
      "learning_rate": 0.000484265,
      "loss": 0.0,
      "step": 3200
    },
    {
      "epoch": 0.32983508245877063,
      "grad_norm": 1.3391427273745649e-05,
      "learning_rate": 0.000483765,
      "loss": 0.0,
      "step": 3300
    },
    {
      "epoch": 0.33983008495752126,
      "grad_norm": 1.0778580872283783e-05,
      "learning_rate": 0.00048326500000000003,
      "loss": 0.0,
      "step": 3400
    },
    {
      "epoch": 0.3498250874562719,
      "grad_norm": 9.422875336895231e-06,
      "learning_rate": 0.000482765,
      "loss": 0.0,
      "step": 3500
    },
    {
      "epoch": 0.3598200899550225,
      "grad_norm": 9.152591701422352e-06,
      "learning_rate": 0.000482265,
      "loss": 0.0,
      "step": 3600
    },
    {
      "epoch": 0.3698150924537731,
      "grad_norm": 8.924918802222237e-06,
      "learning_rate": 0.000481765,
      "loss": 0.0,
      "step": 3700
    },
    {
      "epoch": 0.3798100949525237,
      "grad_norm": 8.906213224690873e-06,
      "learning_rate": 0.00048126500000000003,
      "loss": 0.0,
      "step": 3800
    },
    {
      "epoch": 0.38980509745127434,
      "grad_norm": 8.807169251667801e-06,
      "learning_rate": 0.000480765,
      "loss": 0.0,
      "step": 3900
    },
    {
      "epoch": 0.39980009995002497,
      "grad_norm": 8.804455319477711e-06,
      "learning_rate": 0.000480265,
      "loss": 0.0,
      "step": 4000
    },
    {
      "epoch": 0.4097951024487756,
      "grad_norm": 6.677939836663427e-06,
      "learning_rate": 0.000479765,
      "loss": 0.0,
      "step": 4100
    },
    {
      "epoch": 0.4197901049475262,
      "grad_norm": 5.762084128946299e-06,
      "learning_rate": 0.000479265,
      "loss": 0.0,
      "step": 4200
    },
    {
      "epoch": 0.42978510744627685,
      "grad_norm": 4.242918294039555e-06,
      "learning_rate": 0.00047876500000000003,
      "loss": 0.0,
      "step": 4300
    },
    {
      "epoch": 0.4397801099450275,
      "grad_norm": 3.7372692531789653e-06,
      "learning_rate": 0.000478265,
      "loss": 0.0,
      "step": 4400
    },
    {
      "epoch": 0.4497751124437781,
      "grad_norm": 3.5485109037836082e-06,
      "learning_rate": 0.000477765,
      "loss": 0.0,
      "step": 4500
    },
    {
      "epoch": 0.45977011494252873,
      "grad_norm": 3.4959014101332286e-06,
      "learning_rate": 0.000477265,
      "loss": 0.0,
      "step": 4600
    },
    {
      "epoch": 0.46976511744127936,
      "grad_norm": 3.3235216960747493e-06,
      "learning_rate": 0.000476765,
      "loss": 0.0,
      "step": 4700
    },
    {
      "epoch": 0.47976011994003,
      "grad_norm": 3.2983466553559992e-06,
      "learning_rate": 0.000476265,
      "loss": 0.0,
      "step": 4800
    },
    {
      "epoch": 0.4897551224387806,
      "grad_norm": 3.243136916353251e-06,
      "learning_rate": 0.000475765,
      "loss": 0.0,
      "step": 4900
    },
    {
      "epoch": 0.49975012493753124,
      "grad_norm": 3.2125267352967057e-06,
      "learning_rate": 0.000475265,
      "loss": 0.0,
      "step": 5000
    },
    {
      "epoch": 0.5097451274362819,
      "grad_norm": 3.211607690900564e-06,
      "learning_rate": 0.000474765,
      "loss": 0.0,
      "step": 5100
    },
    {
      "epoch": 0.5197401299350325,
      "grad_norm": 3.1880144888418727e-06,
      "learning_rate": 0.00047426500000000003,
      "loss": 0.0,
      "step": 5200
    },
    {
      "epoch": 0.5297351324337831,
      "grad_norm": 3.195811586920172e-06,
      "learning_rate": 0.000473765,
      "loss": 0.0,
      "step": 5300
    },
    {
      "epoch": 0.5397301349325337,
      "grad_norm": 3.180427484039683e-06,
      "learning_rate": 0.000473265,
      "loss": 0.0,
      "step": 5400
    },
    {
      "epoch": 0.5497251374312844,
      "grad_norm": 3.166011538269231e-06,
      "learning_rate": 0.000472765,
      "loss": 0.0,
      "step": 5500
    },
    {
      "epoch": 0.559720139930035,
      "grad_norm": 3.174174253217643e-06,
      "learning_rate": 0.000472265,
      "loss": 0.0,
      "step": 5600
    },
    {
      "epoch": 0.5697151424287856,
      "grad_norm": 3.1836991638556356e-06,
      "learning_rate": 0.000471765,
      "loss": 0.0,
      "step": 5700
    },
    {
      "epoch": 0.5797101449275363,
      "grad_norm": 2.540086597946356e-06,
      "learning_rate": 0.000471265,
      "loss": 0.0,
      "step": 5800
    },
    {
      "epoch": 0.5897051474262869,
      "grad_norm": 1.6168798993021483e-06,
      "learning_rate": 0.000470765,
      "loss": 0.0,
      "step": 5900
    },
    {
      "epoch": 0.5997001499250375,
      "grad_norm": 1.08556923805736e-06,
      "learning_rate": 0.000470265,
      "loss": 0.0,
      "step": 6000
    },
    {
      "epoch": 0.6096951524237881,
      "grad_norm": 9.247251000488177e-07,
      "learning_rate": 0.00046976499999999997,
      "loss": 0.0,
      "step": 6100
    },
    {
      "epoch": 0.6196901549225388,
      "grad_norm": 6.285370091063669e-07,
      "learning_rate": 0.000469265,
      "loss": 0.0,
      "step": 6200
    },
    {
      "epoch": 0.6296851574212894,
      "grad_norm": 5.294596121530049e-07,
      "learning_rate": 0.000468765,
      "loss": 0.0,
      "step": 6300
    },
    {
      "epoch": 0.63968015992004,
      "grad_norm": 4.628548424534529e-07,
      "learning_rate": 0.000468265,
      "loss": 0.0,
      "step": 6400
    },
    {
      "epoch": 0.6496751624187906,
      "grad_norm": 4.548639083168382e-07,
      "learning_rate": 0.000467765,
      "loss": 0.0,
      "step": 6500
    },
    {
      "epoch": 0.6596701649175413,
      "grad_norm": 3.9354387126877555e-07,
      "learning_rate": 0.000467265,
      "loss": 0.0,
      "step": 6600
    },
    {
      "epoch": 0.6696651674162919,
      "grad_norm": 3.3787841857702006e-07,
      "learning_rate": 0.000466765,
      "loss": 0.0,
      "step": 6700
    },
    {
      "epoch": 0.6796601699150425,
      "grad_norm": 2.9929287848062813e-07,
      "learning_rate": 0.000466265,
      "loss": 0.0,
      "step": 6800
    },
    {
      "epoch": 0.6896551724137931,
      "grad_norm": 2.777680379040248e-07,
      "learning_rate": 0.000465765,
      "loss": 0.0,
      "step": 6900
    },
    {
      "epoch": 0.6996501749125438,
      "grad_norm": 2.3720986064290628e-07,
      "learning_rate": 0.00046526499999999997,
      "loss": 0.0,
      "step": 7000
    },
    {
      "epoch": 0.7096451774112944,
      "grad_norm": 2.314302776085242e-07,
      "learning_rate": 0.000464765,
      "loss": 0.0,
      "step": 7100
    },
    {
      "epoch": 0.719640179910045,
      "grad_norm": 2.1836171981703956e-07,
      "learning_rate": 0.000464265,
      "loss": 0.0,
      "step": 7200
    },
    {
      "epoch": 0.7296351824087957,
      "grad_norm": 2.3195930509700702e-07,
      "learning_rate": 0.000463765,
      "loss": 0.0,
      "step": 7300
    },
    {
      "epoch": 0.7396301849075462,
      "grad_norm": 1.8301511772733647e-07,
      "learning_rate": 0.000463265,
      "loss": 0.0,
      "step": 7400
    },
    {
      "epoch": 0.7496251874062968,
      "grad_norm": 1.8860784223306837e-07,
      "learning_rate": 0.00046276499999999996,
      "loss": 0.0,
      "step": 7500
    },
    {
      "epoch": 0.7596201899050474,
      "grad_norm": 1.7566109988820244e-07,
      "learning_rate": 0.000462265,
      "loss": 0.0,
      "step": 7600
    },
    {
      "epoch": 0.769615192403798,
      "grad_norm": 1.6804582969598414e-07,
      "learning_rate": 0.000461765,
      "loss": 0.0,
      "step": 7700
    },
    {
      "epoch": 0.7796101949025487,
      "grad_norm": 1.5519191265411791e-07,
      "learning_rate": 0.000461265,
      "loss": 0.0,
      "step": 7800
    },
    {
      "epoch": 0.7896051974012993,
      "grad_norm": 1.4417128113564104e-07,
      "learning_rate": 0.00046076499999999997,
      "loss": 0.0,
      "step": 7900
    },
    {
      "epoch": 0.7996001999000499,
      "grad_norm": 1.5987318136012618e-07,
      "learning_rate": 0.000460265,
      "loss": 0.0,
      "step": 8000
    },
    {
      "epoch": 0.8095952023988006,
      "grad_norm": 1.408612035902479e-07,
      "learning_rate": 0.000459765,
      "loss": 0.0,
      "step": 8100
    },
    {
      "epoch": 0.8195902048975512,
      "grad_norm": 1.2580655095462134e-07,
      "learning_rate": 0.000459265,
      "loss": 0.0,
      "step": 8200
    },
    {
      "epoch": 0.8295852073963018,
      "grad_norm": 1.1569498070684858e-07,
      "learning_rate": 0.000458765,
      "loss": 0.0,
      "step": 8300
    },
    {
      "epoch": 0.8395802098950524,
      "grad_norm": 1.1058997984036978e-07,
      "learning_rate": 0.00045826499999999996,
      "loss": 0.0,
      "step": 8400
    },
    {
      "epoch": 0.8495752123938031,
      "grad_norm": 1.0824160057154586e-07,
      "learning_rate": 0.000457765,
      "loss": 0.0,
      "step": 8500
    },
    {
      "epoch": 0.8595702148925537,
      "grad_norm": 1.0233983260832247e-07,
      "learning_rate": 0.000457265,
      "loss": 0.0,
      "step": 8600
    },
    {
      "epoch": 0.8695652173913043,
      "grad_norm": 9.784169208160165e-08,
      "learning_rate": 0.000456765,
      "loss": 0.0,
      "step": 8700
    },
    {
      "epoch": 0.879560219890055,
      "grad_norm": 9.55038430561217e-08,
      "learning_rate": 0.00045626499999999997,
      "loss": 0.0,
      "step": 8800
    },
    {
      "epoch": 0.8895552223888056,
      "grad_norm": 8.981104571148535e-08,
      "learning_rate": 0.000455765,
      "loss": 0.0,
      "step": 8900
    },
    {
      "epoch": 0.8995502248875562,
      "grad_norm": 8.715655752666862e-08,
      "learning_rate": 0.000455265,
      "loss": 0.0,
      "step": 9000
    },
    {
      "epoch": 0.9095452273863068,
      "grad_norm": 8.428118292158615e-08,
      "learning_rate": 0.000454765,
      "loss": 0.0,
      "step": 9100
    },
    {
      "epoch": 0.9195402298850575,
      "grad_norm": 8.108283111596393e-08,
      "learning_rate": 0.000454265,
      "loss": 0.0,
      "step": 9200
    },
    {
      "epoch": 0.9295352323838081,
      "grad_norm": 7.763760834222921e-08,
      "learning_rate": 0.00045376499999999996,
      "loss": 0.0,
      "step": 9300
    },
    {
      "epoch": 0.9395302348825587,
      "grad_norm": 7.46484687397242e-08,
      "learning_rate": 0.000453265,
      "loss": 0.0,
      "step": 9400
    },
    {
      "epoch": 0.9495252373813093,
      "grad_norm": 7.188307904471003e-08,
      "learning_rate": 0.000452765,
      "loss": 0.0,
      "step": 9500
    },
    {
      "epoch": 0.95952023988006,
      "grad_norm": 6.867451673997493e-08,
      "learning_rate": 0.000452265,
      "loss": 0.0,
      "step": 9600
    },
    {
      "epoch": 0.9695152423788106,
      "grad_norm": 6.566449428646592e-08,
      "learning_rate": 0.000451765,
      "loss": 0.0,
      "step": 9700
    },
    {
      "epoch": 0.9795102448775612,
      "grad_norm": 6.286202136607244e-08,
      "learning_rate": 0.000451265,
      "loss": 0.0,
      "step": 9800
    },
    {
      "epoch": 0.9895052473763118,
      "grad_norm": 6.072598068840307e-08,
      "learning_rate": 0.00045076500000000005,
      "loss": 0.0,
      "step": 9900
    },
    {
      "epoch": 0.9995002498750625,
      "grad_norm": 5.7992195934275514e-08,
      "learning_rate": 0.00045026500000000004,
      "loss": 0.0,
      "step": 10000
    },
    {
      "epoch": 1.009495252373813,
      "grad_norm": 1.1472700123249524e-07,
      "learning_rate": 0.00044976500000000003,
      "loss": 0.0,
      "step": 10100
    },
    {
      "epoch": 1.0194902548725637,
      "grad_norm": 5.2332101319052526e-08,
      "learning_rate": 0.000449265,
      "loss": 0.0,
      "step": 10200
    },
    {
      "epoch": 1.0294852573713142,
      "grad_norm": 4.918837959166922e-08,
      "learning_rate": 0.00044876500000000006,
      "loss": 0.0,
      "step": 10300
    },
    {
      "epoch": 1.039480259870065,
      "grad_norm": 4.6959470978436e-08,
      "learning_rate": 0.00044826500000000005,
      "loss": 0.0,
      "step": 10400
    },
    {
      "epoch": 1.0494752623688155,
      "grad_norm": 4.487568716626811e-08,
      "learning_rate": 0.00044776500000000003,
      "loss": 0.0,
      "step": 10500
    },
    {
      "epoch": 1.0594702648675662,
      "grad_norm": 4.27232791366805e-08,
      "learning_rate": 0.000447265,
      "loss": 0.0,
      "step": 10600
    },
    {
      "epoch": 1.0694652673663168,
      "grad_norm": 4.042994206088224e-08,
      "learning_rate": 0.000446765,
      "loss": 0.0,
      "step": 10700
    },
    {
      "epoch": 1.0794602698650675,
      "grad_norm": 3.8393999091113074e-08,
      "learning_rate": 0.00044626500000000005,
      "loss": 0.0,
      "step": 10800
    },
    {
      "epoch": 1.089455272363818,
      "grad_norm": 3.652456470604193e-08,
      "learning_rate": 0.00044576500000000004,
      "loss": 0.0,
      "step": 10900
    },
    {
      "epoch": 1.0994502748625687,
      "grad_norm": 3.481594390564169e-08,
      "learning_rate": 0.000445265,
      "loss": 0.0,
      "step": 11000
    },
    {
      "epoch": 1.1094452773613193,
      "grad_norm": 3.314632124329364e-08,
      "learning_rate": 0.000444765,
      "loss": 0.0,
      "step": 11100
    },
    {
      "epoch": 1.11944027986007,
      "grad_norm": 3.148372940131594e-08,
      "learning_rate": 0.00044426500000000006,
      "loss": 0.0,
      "step": 11200
    },
    {
      "epoch": 1.1294352823588205,
      "grad_norm": 3.005903437269808e-08,
      "learning_rate": 0.00044376500000000004,
      "loss": 0.0,
      "step": 11300
    },
    {
      "epoch": 1.1394302848575713,
      "grad_norm": 2.8384492978261733e-08,
      "learning_rate": 0.00044326500000000003,
      "loss": 0.0,
      "step": 11400
    },
    {
      "epoch": 1.1494252873563218,
      "grad_norm": 2.7089479104347447e-08,
      "learning_rate": 0.000442765,
      "loss": 0.0,
      "step": 11500
    },
    {
      "epoch": 1.1594202898550725,
      "grad_norm": 2.5944915549303005e-08,
      "learning_rate": 0.000442265,
      "loss": 0.0,
      "step": 11600
    },
    {
      "epoch": 1.169415292353823,
      "grad_norm": 2.4231724182754988e-08,
      "learning_rate": 0.00044176500000000005,
      "loss": 0.0,
      "step": 11700
    },
    {
      "epoch": 1.1794102948525738,
      "grad_norm": 2.3375376301260076e-08,
      "learning_rate": 0.00044126500000000004,
      "loss": 0.0,
      "step": 11800
    },
    {
      "epoch": 1.1894052973513243,
      "grad_norm": 2.2195948190528725e-08,
      "learning_rate": 0.000440765,
      "loss": 0.0,
      "step": 11900
    },
    {
      "epoch": 1.199400299850075,
      "grad_norm": 2.0937706679546864e-08,
      "learning_rate": 0.000440265,
      "loss": 0.0,
      "step": 12000
    },
    {
      "epoch": 1.2093953023488255,
      "grad_norm": 8.279689467372009e-08,
      "learning_rate": 0.000439765,
      "loss": 0.0,
      "step": 12100
    },
    {
      "epoch": 1.2193903048475763,
      "grad_norm": 2.2449244241329325e-08,
      "learning_rate": 0.00043926500000000004,
      "loss": 0.0,
      "step": 12200
    },
    {
      "epoch": 1.2293853073463268,
      "grad_norm": 1.625390488868561e-08,
      "learning_rate": 0.00043876500000000003,
      "loss": 0.0,
      "step": 12300
    },
    {
      "epoch": 1.2393803098450775,
      "grad_norm": 1.521868497889045e-08,
      "learning_rate": 0.000438265,
      "loss": 0.0,
      "step": 12400
    },
    {
      "epoch": 1.249375312343828,
      "grad_norm": 1.4383375379622976e-08,
      "learning_rate": 0.000437765,
      "loss": 0.0,
      "step": 12500
    },
    {
      "epoch": 1.2593703148425788,
      "grad_norm": 1.3560395473177778e-08,
      "learning_rate": 0.00043726500000000005,
      "loss": 0.0,
      "step": 12600
    },
    {
      "epoch": 1.2693653173413293,
      "grad_norm": 1.2850986053081215e-08,
      "learning_rate": 0.00043676500000000004,
      "loss": 0.0,
      "step": 12700
    },
    {
      "epoch": 1.27936031984008,
      "grad_norm": 1.2373921443042946e-08,
      "learning_rate": 0.000436265,
      "loss": 0.0,
      "step": 12800
    },
    {
      "epoch": 1.2893553223388305,
      "grad_norm": 1.1592899085144381e-08,
      "learning_rate": 0.000435765,
      "loss": 0.0,
      "step": 12900
    },
    {
      "epoch": 1.2993503248375813,
      "grad_norm": 1.1003221445093914e-08,
      "learning_rate": 0.000435265,
      "loss": 0.0,
      "step": 13000
    },
    {
      "epoch": 1.3093453273363318,
      "grad_norm": 1.0666129313108286e-08,
      "learning_rate": 0.00043476500000000004,
      "loss": 0.0,
      "step": 13100
    },
    {
      "epoch": 1.3193403298350825,
      "grad_norm": 1.0214208145953307e-08,
      "learning_rate": 0.00043426500000000003,
      "loss": 0.0,
      "step": 13200
    },
    {
      "epoch": 1.329335332333833,
      "grad_norm": 9.653012611465783e-09,
      "learning_rate": 0.000433765,
      "loss": 0.0,
      "step": 13300
    },
    {
      "epoch": 1.3393303348325838,
      "grad_norm": 9.084916818835609e-09,
      "learning_rate": 0.000433265,
      "loss": 0.0,
      "step": 13400
    },
    {
      "epoch": 1.3493253373313343,
      "grad_norm": 8.521593208854483e-09,
      "learning_rate": 0.000432765,
      "loss": 0.0,
      "step": 13500
    },
    {
      "epoch": 1.3593203398300848,
      "grad_norm": 7.97333932212041e-09,
      "learning_rate": 0.00043226500000000004,
      "loss": 0.0,
      "step": 13600
    },
    {
      "epoch": 1.3693153423288356,
      "grad_norm": 7.481785857521572e-09,
      "learning_rate": 0.000431765,
      "loss": 0.0,
      "step": 13700
    },
    {
      "epoch": 1.3793103448275863,
      "grad_norm": 7.209535635155362e-09,
      "learning_rate": 0.000431265,
      "loss": 0.0,
      "step": 13800
    },
    {
      "epoch": 1.3893053473263368,
      "grad_norm": 7.188092343568542e-09,
      "learning_rate": 0.000430765,
      "loss": 0.0,
      "step": 13900
    },
    {
      "epoch": 1.3993003498250873,
      "grad_norm": 6.9704251259850025e-09,
      "learning_rate": 0.00043026500000000004,
      "loss": 0.0,
      "step": 14000
    },
    {
      "epoch": 1.409295352323838,
      "grad_norm": 5.0130402939885244e-08,
      "learning_rate": 0.00042976500000000003,
      "loss": 0.0,
      "step": 14100
    },
    {
      "epoch": 1.4192903548225888,
      "grad_norm": 2.0007218992645903e-08,
      "learning_rate": 0.000429265,
      "loss": 0.0,
      "step": 14200
    },
    {
      "epoch": 1.4292853573213393,
      "grad_norm": 7.922880129740406e-09,
      "learning_rate": 0.000428765,
      "loss": 0.0,
      "step": 14300
    },
    {
      "epoch": 1.4392803598200898,
      "grad_norm": 5.056896235089425e-09,
      "learning_rate": 0.000428265,
      "loss": 0.0,
      "step": 14400
    },
    {
      "epoch": 1.4492753623188406,
      "grad_norm": 2.1227075208685164e-08,
      "learning_rate": 0.00042776500000000004,
      "loss": 0.0,
      "step": 14500
    },
    {
      "epoch": 1.4592703648175913,
      "grad_norm": 4.192196367824863e-09,
      "learning_rate": 0.000427265,
      "loss": 0.0,
      "step": 14600
    },
    {
      "epoch": 1.4692653673163418,
      "grad_norm": 4.02192901205467e-09,
      "learning_rate": 0.000426765,
      "loss": 0.0,
      "step": 14700
    },
    {
      "epoch": 1.4792603698150923,
      "grad_norm": 3.948825266775202e-09,
      "learning_rate": 0.000426265,
      "loss": 0.0,
      "step": 14800
    },
    {
      "epoch": 1.489255372313843,
      "grad_norm": 3.8858640749595e-09,
      "learning_rate": 0.000425765,
      "loss": 0.0,
      "step": 14900
    },
    {
      "epoch": 1.4992503748125938,
      "grad_norm": 3.762164357823394e-09,
      "learning_rate": 0.00042526500000000003,
      "loss": 0.0,
      "step": 15000
    },
    {
      "epoch": 1.5092453773113443,
      "grad_norm": 3.53943252484612e-09,
      "learning_rate": 0.000424765,
      "loss": 0.0,
      "step": 15100
    },
    {
      "epoch": 1.5192403798100949,
      "grad_norm": 3.1242941567199978e-09,
      "learning_rate": 0.000424265,
      "loss": 0.0,
      "step": 15200
    },
    {
      "epoch": 1.5292353823088456,
      "grad_norm": 2.8879756364119658e-09,
      "learning_rate": 0.000423765,
      "loss": 0.0,
      "step": 15300
    },
    {
      "epoch": 1.5392303848075963,
      "grad_norm": 2.8289346420962147e-09,
      "learning_rate": 0.00042326500000000003,
      "loss": 0.0,
      "step": 15400
    },
    {
      "epoch": 1.5492253873063468,
      "grad_norm": 2.6740085701248972e-09,
      "learning_rate": 0.000422765,
      "loss": 0.0,
      "step": 15500
    },
    {
      "epoch": 1.5592203898050974,
      "grad_norm": 2.7106095146223197e-09,
      "learning_rate": 0.000422265,
      "loss": 0.0,
      "step": 15600
    },
    {
      "epoch": 1.569215392303848,
      "grad_norm": 2.6432263044995352e-09,
      "learning_rate": 0.000421765,
      "loss": 0.0,
      "step": 15700
    },
    {
      "epoch": 1.5792103948025988,
      "grad_norm": 2.752083005930217e-09,
      "learning_rate": 0.000421265,
      "loss": 0.0,
      "step": 15800
    },
    {
      "epoch": 1.5892053973013494,
      "grad_norm": 2.7999425000757583e-09,
      "learning_rate": 0.00042076500000000003,
      "loss": 0.0,
      "step": 15900
    },
    {
      "epoch": 1.5992003998000999,
      "grad_norm": 2.5401778458444824e-09,
      "learning_rate": 0.000420265,
      "loss": 0.0,
      "step": 16000
    },
    {
      "epoch": 1.6091954022988506,
      "grad_norm": 2.8369916194037614e-08,
      "learning_rate": 0.000419765,
      "loss": 0.0,
      "step": 16100
    },
    {
      "epoch": 1.6191904047976013,
      "grad_norm": 1.7545968233889653e-08,
      "learning_rate": 0.000419265,
      "loss": 0.0,
      "step": 16200
    },
    {
      "epoch": 1.6291854072963519,
      "grad_norm": 9.2526999395659e-09,
      "learning_rate": 0.00041876500000000003,
      "loss": 0.0,
      "step": 16300
    },
    {
      "epoch": 1.6391804097951024,
      "grad_norm": 4.313109425169159e-09,
      "learning_rate": 0.000418265,
      "loss": 0.0,
      "step": 16400
    },
    {
      "epoch": 1.6491754122938531,
      "grad_norm": 2.550047950578005e-09,
      "learning_rate": 0.000417765,
      "loss": 0.0,
      "step": 16500
    },
    {
      "epoch": 1.6591704147926039,
      "grad_norm": 1.8671908463829823e-09,
      "learning_rate": 0.000417265,
      "loss": 0.0,
      "step": 16600
    },
    {
      "epoch": 1.6691654172913544,
      "grad_norm": 1.991440568005487e-09,
      "learning_rate": 0.000416765,
      "loss": 0.0,
      "step": 16700
    },
    {
      "epoch": 1.6791604197901049,
      "grad_norm": 1.6245861322872202e-09,
      "learning_rate": 0.000416265,
      "loss": 0.0,
      "step": 16800
    },
    {
      "epoch": 1.6891554222888556,
      "grad_norm": 1.8203069052091791e-09,
      "learning_rate": 0.000415765,
      "loss": 0.0,
      "step": 16900
    },
    {
      "epoch": 1.6991504247876064,
      "grad_norm": 1.580058195393974e-09,
      "learning_rate": 0.000415265,
      "loss": 0.0,
      "step": 17000
    },
    {
      "epoch": 1.7091454272863569,
      "grad_norm": 1.3608552063004709e-09,
      "learning_rate": 0.000414765,
      "loss": 0.0,
      "step": 17100
    },
    {
      "epoch": 1.7191404297851074,
      "grad_norm": 1.2164542706472048e-09,
      "learning_rate": 0.000414265,
      "loss": 0.0,
      "step": 17200
    },
    {
      "epoch": 1.729135432283858,
      "grad_norm": 1.1813940936633571e-09,
      "learning_rate": 0.000413765,
      "loss": 0.0,
      "step": 17300
    },
    {
      "epoch": 1.7391304347826086,
      "grad_norm": 1.1727585569332177e-09,
      "learning_rate": 0.000413265,
      "loss": 0.0,
      "step": 17400
    },
    {
      "epoch": 1.7491254372813594,
      "grad_norm": 9.095652009349919e-10,
      "learning_rate": 0.000412765,
      "loss": 0.0,
      "step": 17500
    },
    {
      "epoch": 1.75912043978011,
      "grad_norm": 1.1372710551071918e-09,
      "learning_rate": 0.000412265,
      "loss": 0.0,
      "step": 17600
    },
    {
      "epoch": 1.7691154422788604,
      "grad_norm": 9.042609994125428e-10,
      "learning_rate": 0.000411765,
      "loss": 0.0,
      "step": 17700
    },
    {
      "epoch": 1.7791104447776112,
      "grad_norm": 1.0229177505038933e-09,
      "learning_rate": 0.000411265,
      "loss": 0.0,
      "step": 17800
    },
    {
      "epoch": 1.789105447276362,
      "grad_norm": 9.28218502060929e-10,
      "learning_rate": 0.000410765,
      "loss": 0.0,
      "step": 17900
    },
    {
      "epoch": 1.7991004497751124,
      "grad_norm": 9.197687056428094e-10,
      "learning_rate": 0.000410265,
      "loss": 0.0,
      "step": 18000
    },
    {
      "epoch": 1.809095452273863,
      "grad_norm": 1.5105850792451747e-08,
      "learning_rate": 0.000409765,
      "loss": 0.0,
      "step": 18100
    },
    {
      "epoch": 1.8190904547726137,
      "grad_norm": 1.39330458281961e-08,
      "learning_rate": 0.000409265,
      "loss": 0.0,
      "step": 18200
    },
    {
      "epoch": 1.8290854572713644,
      "grad_norm": 1.0099865832557953e-08,
      "learning_rate": 0.000408765,
      "loss": 0.0,
      "step": 18300
    },
    {
      "epoch": 1.839080459770115,
      "grad_norm": 6.3415486195594895e-09,
      "learning_rate": 0.000408265,
      "loss": 0.0,
      "step": 18400
    },
    {
      "epoch": 1.8490754622688654,
      "grad_norm": 4.674291620432314e-09,
      "learning_rate": 0.000407765,
      "loss": 0.0,
      "step": 18500
    },
    {
      "epoch": 1.8590704647676162,
      "grad_norm": 3.0107976112248025e-09,
      "learning_rate": 0.00040726499999999997,
      "loss": 0.0,
      "step": 18600
    },
    {
      "epoch": 1.869065467266367,
      "grad_norm": 2.079676653110596e-09,
      "learning_rate": 0.000406765,
      "loss": 0.0,
      "step": 18700
    },
    {
      "epoch": 1.8790604697651174,
      "grad_norm": 1.3071170812395394e-09,
      "learning_rate": 0.000406265,
      "loss": 0.0,
      "step": 18800
    },
    {
      "epoch": 1.889055472263868,
      "grad_norm": 6.360900695057126e-09,
      "learning_rate": 0.000405765,
      "loss": 0.0,
      "step": 18900
    },
    {
      "epoch": 1.8990504747626187,
      "grad_norm": 1.0664290561734902e-09,
      "learning_rate": 0.000405265,
      "loss": 0.0,
      "step": 19000
    },
    {
      "epoch": 1.9090454772613694,
      "grad_norm": 1.0114904469560315e-09,
      "learning_rate": 0.000404765,
      "loss": 0.0,
      "step": 19100
    },
    {
      "epoch": 1.91904047976012,
      "grad_norm": 7.250492428667599e-10,
      "learning_rate": 0.000404265,
      "loss": 0.0,
      "step": 19200
    },
    {
      "epoch": 1.9290354822588704,
      "grad_norm": 7.763509279890002e-10,
      "learning_rate": 0.000403765,
      "loss": 0.0,
      "step": 19300
    },
    {
      "epoch": 1.9390304847576212,
      "grad_norm": 5.920909873502467e-10,
      "learning_rate": 0.000403265,
      "loss": 0.0,
      "step": 19400
    },
    {
      "epoch": 1.949025487256372,
      "grad_norm": 8.399337891873415e-10,
      "learning_rate": 0.00040276499999999997,
      "loss": 0.0,
      "step": 19500
    },
    {
      "epoch": 1.9590204897551224,
      "grad_norm": 7.108811872491572e-10,
      "learning_rate": 0.000402265,
      "loss": 0.0,
      "step": 19600
    },
    {
      "epoch": 1.969015492253873,
      "grad_norm": 7.73362873740524e-10,
      "learning_rate": 0.000401765,
      "loss": 0.0,
      "step": 19700
    },
    {
      "epoch": 1.9790104947526237,
      "grad_norm": 7.005158120243493e-10,
      "learning_rate": 0.000401265,
      "loss": 0.0,
      "step": 19800
    },
    {
      "epoch": 1.9890054972513744,
      "grad_norm": 7.249053579627684e-10,
      "learning_rate": 0.000400765,
      "loss": 0.0,
      "step": 19900
    },
    {
      "epoch": 1.999000499750125,
      "grad_norm": 7.702923854324695e-10,
      "learning_rate": 0.00040026499999999996,
      "loss": 0.0,
      "step": 20000
    },
    {
      "epoch": 2.0089955022488755,
      "grad_norm": 7.954576553004244e-09,
      "learning_rate": 0.000399765,
      "loss": 0.0,
      "step": 20100
    },
    {
      "epoch": 2.018990504747626,
      "grad_norm": 7.911220123446583e-09,
      "learning_rate": 0.000399265,
      "loss": 0.0,
      "step": 20200
    },
    {
      "epoch": 2.028985507246377,
      "grad_norm": 7.554016079325265e-09,
      "learning_rate": 0.000398765,
      "loss": 0.0,
      "step": 20300
    },
    {
      "epoch": 2.0389805097451275,
      "grad_norm": 6.240354011310956e-09,
      "learning_rate": 0.00039826499999999997,
      "loss": 0.0,
      "step": 20400
    },
    {
      "epoch": 2.048975512243878,
      "grad_norm": 5.493776988885202e-09,
      "learning_rate": 0.000397765,
      "loss": 0.0,
      "step": 20500
    },
    {
      "epoch": 2.0589705147426285,
      "grad_norm": 4.359172578460857e-09,
      "learning_rate": 0.000397265,
      "loss": 0.0,
      "step": 20600
    },
    {
      "epoch": 2.0689655172413794,
      "grad_norm": 3.574494478186807e-09,
      "learning_rate": 0.000396765,
      "loss": 0.0,
      "step": 20700
    },
    {
      "epoch": 2.07896051974013,
      "grad_norm": 3.0290310260028264e-09,
      "learning_rate": 0.000396265,
      "loss": 0.0,
      "step": 20800
    },
    {
      "epoch": 2.0889555222388805,
      "grad_norm": 2.244753716240666e-09,
      "learning_rate": 0.00039576499999999996,
      "loss": 0.0,
      "step": 20900
    },
    {
      "epoch": 2.098950524737631,
      "grad_norm": 2.1024217922160915e-09,
      "learning_rate": 0.000395265,
      "loss": 0.0,
      "step": 21000
    },
    {
      "epoch": 2.108945527236382,
      "grad_norm": 1.4154803995580778e-09,
      "learning_rate": 0.000394765,
      "loss": 0.0,
      "step": 21100
    },
    {
      "epoch": 2.1189405297351325,
      "grad_norm": 1.114194847495753e-09,
      "learning_rate": 0.000394265,
      "loss": 0.0,
      "step": 21200
    },
    {
      "epoch": 2.128935532233883,
      "grad_norm": 1.0749245937802243e-09,
      "learning_rate": 0.00039376499999999997,
      "loss": 0.0,
      "step": 21300
    },
    {
      "epoch": 2.1389305347326335,
      "grad_norm": 8.509790649924298e-10,
      "learning_rate": 0.000393265,
      "loss": 0.0,
      "step": 21400
    },
    {
      "epoch": 2.1489255372313845,
      "grad_norm": 8.344989699260452e-10,
      "learning_rate": 0.000392765,
      "loss": 0.0,
      "step": 21500
    },
    {
      "epoch": 2.158920539730135,
      "grad_norm": 6.683446573951812e-10,
      "learning_rate": 0.000392265,
      "loss": 0.0,
      "step": 21600
    },
    {
      "epoch": 2.1689155422288855,
      "grad_norm": 7.12032377503391e-10,
      "learning_rate": 0.000391765,
      "loss": 0.0,
      "step": 21700
    },
    {
      "epoch": 2.178910544727636,
      "grad_norm": 6.627631221611807e-10,
      "learning_rate": 0.00039126499999999996,
      "loss": 0.0,
      "step": 21800
    },
    {
      "epoch": 2.188905547226387,
      "grad_norm": 6.050696055304172e-10,
      "learning_rate": 0.000390765,
      "loss": 0.0,
      "step": 21900
    },
    {
      "epoch": 2.1989005497251375,
      "grad_norm": 5.981694028989182e-10,
      "learning_rate": 0.000390265,
      "loss": 0.0,
      "step": 22000
    },
    {
      "epoch": 2.208895552223888,
      "grad_norm": 4.195839231613263e-09,
      "learning_rate": 0.000389765,
      "loss": 0.0,
      "step": 22100
    },
    {
      "epoch": 2.2188905547226385,
      "grad_norm": 4.191599067837615e-09,
      "learning_rate": 0.000389265,
      "loss": 0.0,
      "step": 22200
    },
    {
      "epoch": 2.2288855572213895,
      "grad_norm": 4.1794829819252755e-09,
      "learning_rate": 0.000388765,
      "loss": 0.0,
      "step": 22300
    },
    {
      "epoch": 2.23888055972014,
      "grad_norm": 4.1386956084465965e-09,
      "learning_rate": 0.00038826500000000005,
      "loss": 0.0,
      "step": 22400
    },
    {
      "epoch": 2.2488755622188905,
      "grad_norm": 4.040578538422324e-09,
      "learning_rate": 0.00038776500000000004,
      "loss": 0.0,
      "step": 22500
    },
    {
      "epoch": 2.258870564717641,
      "grad_norm": 3.8039345007234715e-09,
      "learning_rate": 0.000387265,
      "loss": 0.0,
      "step": 22600
    },
    {
      "epoch": 2.268865567216392,
      "grad_norm": 3.4218934352736596e-09,
      "learning_rate": 0.000386765,
      "loss": 0.0,
      "step": 22700
    },
    {
      "epoch": 2.2788605697151425,
      "grad_norm": 3.1313713844127733e-09,
      "learning_rate": 0.00038626500000000006,
      "loss": 0.0,
      "step": 22800
    },
    {
      "epoch": 2.288855572213893,
      "grad_norm": 2.649197972104389e-09,
      "learning_rate": 0.00038576500000000004,
      "loss": 0.0,
      "step": 22900
    },
    {
      "epoch": 2.2988505747126435,
      "grad_norm": 2.598002923903664e-09,
      "learning_rate": 0.00038526500000000003,
      "loss": 0.0,
      "step": 23000
    },
    {
      "epoch": 2.3088455772113945,
      "grad_norm": 2.283950806258872e-09,
      "learning_rate": 0.000384765,
      "loss": 0.0,
      "step": 23100
    },
    {
      "epoch": 2.318840579710145,
      "grad_norm": 2.119006525802547e-09,
      "learning_rate": 0.000384265,
      "loss": 0.0,
      "step": 23200
    },
    {
      "epoch": 2.3288355822088955,
      "grad_norm": 1.901321100561404e-09,
      "learning_rate": 0.00038376500000000005,
      "loss": 0.0,
      "step": 23300
    },
    {
      "epoch": 2.338830584707646,
      "grad_norm": 1.7248913408707267e-09,
      "learning_rate": 0.00038326500000000004,
      "loss": 0.0,
      "step": 23400
    },
    {
      "epoch": 2.348825587206397,
      "grad_norm": 1.671247029655376e-09,
      "learning_rate": 0.000382765,
      "loss": 0.0,
      "step": 23500
    },
    {
      "epoch": 2.3588205897051475,
      "grad_norm": 1.3062957382459217e-09,
      "learning_rate": 0.000382265,
      "loss": 0.0,
      "step": 23600
    },
    {
      "epoch": 2.368815592203898,
      "grad_norm": 1.247110303914667e-09,
      "learning_rate": 0.00038176500000000006,
      "loss": 0.0,
      "step": 23700
    },
    {
      "epoch": 2.3788105947026486,
      "grad_norm": 1.1634792018710982e-09,
      "learning_rate": 0.00038126500000000004,
      "loss": 0.0,
      "step": 23800
    },
    {
      "epoch": 2.388805597201399,
      "grad_norm": 1.056468801330368e-09,
      "learning_rate": 0.00038076500000000003,
      "loss": 0.0,
      "step": 23900
    },
    {
      "epoch": 2.39880059970015,
      "grad_norm": 9.627985075866263e-10,
      "learning_rate": 0.000380265,
      "loss": 0.0,
      "step": 24000
    },
    {
      "epoch": 2.4087956021989005,
      "grad_norm": 2.2001791499803858e-09,
      "learning_rate": 0.000379765,
      "loss": 0.0,
      "step": 24100
    },
    {
      "epoch": 2.418790604697651,
      "grad_norm": 2.1945665285016958e-09,
      "learning_rate": 0.00037926500000000005,
      "loss": 0.0,
      "step": 24200
    },
    {
      "epoch": 2.428785607196402,
      "grad_norm": 2.196962389788837e-09,
      "learning_rate": 0.00037876500000000004,
      "loss": 0.0,
      "step": 24300
    },
    {
      "epoch": 2.4387806096951525,
      "grad_norm": 2.199997739538162e-09,
      "learning_rate": 0.000378265,
      "loss": 0.0,
      "step": 24400
    },
    {
      "epoch": 2.448775612193903,
      "grad_norm": 2.2028197044221542e-09,
      "learning_rate": 0.000377765,
      "loss": 0.0,
      "step": 24500
    },
    {
      "epoch": 2.4587706146926536,
      "grad_norm": 2.203990545623924e-09,
      "learning_rate": 0.000377265,
      "loss": 0.0,
      "step": 24600
    },
    {
      "epoch": 2.468765617191404,
      "grad_norm": 2.221180572803405e-09,
      "learning_rate": 0.00037676500000000004,
      "loss": 0.0,
      "step": 24700
    },
    {
      "epoch": 2.478760619690155,
      "grad_norm": 2.2000621324735903e-09,
      "learning_rate": 0.00037626500000000003,
      "loss": 0.0,
      "step": 24800
    },
    {
      "epoch": 2.4887556221889056,
      "grad_norm": 2.1898189928037937e-09,
      "learning_rate": 0.000375765,
      "loss": 0.0,
      "step": 24900
    },
    {
      "epoch": 2.498750624687656,
      "grad_norm": 2.1842356812129538e-09,
      "learning_rate": 0.000375265,
      "loss": 0.0,
      "step": 25000
    },
    {
      "epoch": 2.508745627186407,
      "grad_norm": 2.163857315551354e-09,
      "learning_rate": 0.00037476500000000005,
      "loss": 0.0,
      "step": 25100
    },
    {
      "epoch": 2.5187406296851576,
      "grad_norm": 2.127803711005072e-09,
      "learning_rate": 0.00037426500000000004,
      "loss": 0.0,
      "step": 25200
    },
    {
      "epoch": 2.528735632183908,
      "grad_norm": 2.073895055687558e-09,
      "learning_rate": 0.000373765,
      "loss": 0.0,
      "step": 25300
    },
    {
      "epoch": 2.5387306346826586,
      "grad_norm": 1.9719299526599343e-09,
      "learning_rate": 0.000373265,
      "loss": 0.0,
      "step": 25400
    },
    {
      "epoch": 2.548725637181409,
      "grad_norm": 1.9192591960148775e-09,
      "learning_rate": 0.000372765,
      "loss": 0.0,
      "step": 25500
    },
    {
      "epoch": 2.55872063968016,
      "grad_norm": 1.8318078165435736e-09,
      "learning_rate": 0.00037226500000000004,
      "loss": 0.0,
      "step": 25600
    },
    {
      "epoch": 2.5687156421789106,
      "grad_norm": 1.7493175796801097e-09,
      "learning_rate": 0.00037176500000000003,
      "loss": 0.0,
      "step": 25700
    },
    {
      "epoch": 2.578710644677661,
      "grad_norm": 1.7718142508726942e-09,
      "learning_rate": 0.000371265,
      "loss": 0.0,
      "step": 25800
    },
    {
      "epoch": 2.588705647176412,
      "grad_norm": 1.613172928571771e-09,
      "learning_rate": 0.000370765,
      "loss": 0.0,
      "step": 25900
    },
    {
      "epoch": 2.5987006496751626,
      "grad_norm": 1.577549979536741e-09,
      "learning_rate": 0.000370265,
      "loss": 0.0,
      "step": 26000
    },
    {
      "epoch": 2.608695652173913,
      "grad_norm": 1.1267941024684092e-09,
      "learning_rate": 0.00036976500000000004,
      "loss": 0.0,
      "step": 26100
    },
    {
      "epoch": 2.6186906546726636,
      "grad_norm": 1.1247216491483414e-09,
      "learning_rate": 0.000369265,
      "loss": 0.0,
      "step": 26200
    },
    {
      "epoch": 2.628685657171414,
      "grad_norm": 1.1559371237979121e-09,
      "learning_rate": 0.000368765,
      "loss": 0.0,
      "step": 26300
    },
    {
      "epoch": 2.638680659670165,
      "grad_norm": 1.1217198281343599e-09,
      "learning_rate": 0.000368265,
      "loss": 0.0,
      "step": 26400
    },
    {
      "epoch": 2.6486756621689156,
      "grad_norm": 1.1218690421088695e-09,
      "learning_rate": 0.00036776500000000004,
      "loss": 0.0,
      "step": 26500
    },
    {
      "epoch": 2.658670664667666,
      "grad_norm": 1.1227310192651885e-09,
      "learning_rate": 0.00036726500000000003,
      "loss": 0.0,
      "step": 26600
    },
    {
      "epoch": 2.668665667166417,
      "grad_norm": 1.126211013335876e-09,
      "learning_rate": 0.000366765,
      "loss": 0.0,
      "step": 26700
    },
    {
      "epoch": 2.6786606696651676,
      "grad_norm": 1.1229528418255086e-09,
      "learning_rate": 0.000366265,
      "loss": 0.0,
      "step": 26800
    },
    {
      "epoch": 2.688655672163918,
      "grad_norm": 1.1239910113758356e-09,
      "learning_rate": 0.000365765,
      "loss": 0.0,
      "step": 26900
    },
    {
      "epoch": 2.6986506746626686,
      "grad_norm": 1.1267772270784349e-09,
      "learning_rate": 0.00036526500000000003,
      "loss": 0.0,
      "step": 27000
    },
    {
      "epoch": 2.708645677161419,
      "grad_norm": 1.1240678388091396e-09,
      "learning_rate": 0.000364765,
      "loss": 0.0,
      "step": 27100
    },
    {
      "epoch": 2.7186406796601696,
      "grad_norm": 1.1243934672222622e-09,
      "learning_rate": 0.000364265,
      "loss": 0.0,
      "step": 27200
    },
    {
      "epoch": 2.7286356821589206,
      "grad_norm": 1.1254345233524532e-09,
      "learning_rate": 0.000363765,
      "loss": 0.0,
      "step": 27300
    },
    {
      "epoch": 2.738630684657671,
      "grad_norm": 1.1271569233528567e-09,
      "learning_rate": 0.000363265,
      "loss": 0.0,
      "step": 27400
    },
    {
      "epoch": 2.7486256871564216,
      "grad_norm": 1.126812310126013e-09,
      "learning_rate": 0.00036276500000000003,
      "loss": 0.0,
      "step": 27500
    },
    {
      "epoch": 2.7586206896551726,
      "grad_norm": 1.128084736734536e-09,
      "learning_rate": 0.000362265,
      "loss": 0.0,
      "step": 27600
    },
    {
      "epoch": 2.768615692153923,
      "grad_norm": 1.020807216534081e-09,
      "learning_rate": 0.000361765,
      "loss": 0.0,
      "step": 27700
    },
    {
      "epoch": 2.7786106946526736,
      "grad_norm": 1.1295611113126824e-09,
      "learning_rate": 0.000361265,
      "loss": 0.0,
      "step": 27800
    },
    {
      "epoch": 2.788605697151424,
      "grad_norm": 1.1291058088502837e-09,
      "learning_rate": 0.00036076500000000003,
      "loss": 0.0,
      "step": 27900
    },
    {
      "epoch": 2.7986006996501747,
      "grad_norm": 1.1294689628016386e-09,
      "learning_rate": 0.000360265,
      "loss": 0.0,
      "step": 28000
    },
    {
      "epoch": 2.8085957021489256,
      "grad_norm": 1.0514481507684081e-09,
      "learning_rate": 0.000359765,
      "loss": 0.0,
      "step": 28100
    },
    {
      "epoch": 2.818590704647676,
      "grad_norm": 1.0478097278721066e-09,
      "learning_rate": 0.000359265,
      "loss": 0.0,
      "step": 28200
    },
    {
      "epoch": 2.8285857071464267,
      "grad_norm": 1.0421294938112169e-09,
      "learning_rate": 0.000358765,
      "loss": 0.0,
      "step": 28300
    },
    {
      "epoch": 2.8385807096451776,
      "grad_norm": 1.0359600954856774e-09,
      "learning_rate": 0.000358265,
      "loss": 0.0,
      "step": 28400
    },
    {
      "epoch": 2.848575712143928,
      "grad_norm": 1.0366117964011323e-09,
      "learning_rate": 0.000357765,
      "loss": 0.0,
      "step": 28500
    },
    {
      "epoch": 2.8585707146426786,
      "grad_norm": 1.015265427284362e-09,
      "learning_rate": 0.000357265,
      "loss": 0.0,
      "step": 28600
    },
    {
      "epoch": 2.868565717141429,
      "grad_norm": 1.0229606051126439e-09,
      "learning_rate": 0.000356765,
      "loss": 0.0,
      "step": 28700
    },
    {
      "epoch": 2.8785607196401797,
      "grad_norm": 1.0231170355368135e-09,
      "learning_rate": 0.00035626500000000003,
      "loss": 0.0,
      "step": 28800
    },
    {
      "epoch": 2.8885557221389306,
      "grad_norm": 1.0146574691560772e-09,
      "learning_rate": 0.000355765,
      "loss": 0.0,
      "step": 28900
    },
    {
      "epoch": 2.898550724637681,
      "grad_norm": 1.0025871244323525e-09,
      "learning_rate": 0.000355265,
      "loss": 0.0,
      "step": 29000
    },
    {
      "epoch": 2.9085457271364317,
      "grad_norm": 1.0154774798820654e-09,
      "learning_rate": 0.000354765,
      "loss": 0.0,
      "step": 29100
    },
    {
      "epoch": 2.9185407296351826,
      "grad_norm": 9.84527570579985e-10,
      "learning_rate": 0.000354265,
      "loss": 0.0,
      "step": 29200
    },
    {
      "epoch": 2.928535732133933,
      "grad_norm": 9.967493497242685e-10,
      "learning_rate": 0.000353765,
      "loss": 0.0,
      "step": 29300
    },
    {
      "epoch": 2.9385307346326837,
      "grad_norm": 9.709392179146903e-10,
      "learning_rate": 0.000353265,
      "loss": 0.0,
      "step": 29400
    },
    {
      "epoch": 2.948525737131434,
      "grad_norm": 9.650954480022733e-10,
      "learning_rate": 0.000352765,
      "loss": 0.0,
      "step": 29500
    },
    {
      "epoch": 2.9585207396301847,
      "grad_norm": 9.519031118898624e-10,
      "learning_rate": 0.000352265,
      "loss": 0.0,
      "step": 29600
    },
    {
      "epoch": 2.9685157421289357,
      "grad_norm": 9.500785713711934e-10,
      "learning_rate": 0.000351765,
      "loss": 0.0,
      "step": 29700
    },
    {
      "epoch": 2.978510744627686,
      "grad_norm": 9.543760226549125e-10,
      "learning_rate": 0.000351265,
      "loss": 0.0,
      "step": 29800
    },
    {
      "epoch": 2.9885057471264367,
      "grad_norm": 9.52351419947206e-10,
      "learning_rate": 0.000350765,
      "loss": 0.0,
      "step": 29900
    },
    {
      "epoch": 2.9985007496251876,
      "grad_norm": 9.363785302696215e-10,
      "learning_rate": 0.000350265,
      "loss": 0.0,
      "step": 30000
    },
    {
      "epoch": 3.008495752123938,
      "grad_norm": 9.450280558098711e-10,
      "learning_rate": 0.000349765,
      "loss": 0.0,
      "step": 30100
    },
    {
      "epoch": 3.0184907546226887,
      "grad_norm": 9.491931685090549e-10,
      "learning_rate": 0.000349265,
      "loss": 0.0,
      "step": 30200
    },
    {
      "epoch": 3.028485757121439,
      "grad_norm": 9.424914182432076e-10,
      "learning_rate": 0.000348765,
      "loss": 0.0,
      "step": 30300
    },
    {
      "epoch": 3.0384807596201897,
      "grad_norm": 9.496908814909943e-10,
      "learning_rate": 0.000348265,
      "loss": 0.0,
      "step": 30400
    },
    {
      "epoch": 3.0484757621189407,
      "grad_norm": 9.418248403392226e-10,
      "learning_rate": 0.000347765,
      "loss": 0.0,
      "step": 30500
    },
    {
      "epoch": 3.058470764617691,
      "grad_norm": 9.31506094481449e-10,
      "learning_rate": 0.000347265,
      "loss": 0.0,
      "step": 30600
    },
    {
      "epoch": 3.0684657671164417,
      "grad_norm": 9.29681776007385e-10,
      "learning_rate": 0.000346765,
      "loss": 0.0,
      "step": 30700
    },
    {
      "epoch": 3.078460769615192,
      "grad_norm": 9.35042820948695e-10,
      "learning_rate": 0.000346265,
      "loss": 0.0,
      "step": 30800
    },
    {
      "epoch": 3.088455772113943,
      "grad_norm": 9.351741603325081e-10,
      "learning_rate": 0.000345765,
      "loss": 0.0,
      "step": 30900
    },
    {
      "epoch": 3.0984507746126937,
      "grad_norm": 9.23978893396793e-10,
      "learning_rate": 0.000345265,
      "loss": 0.0,
      "step": 31000
    },
    {
      "epoch": 3.108445777111444,
      "grad_norm": 9.049616611633837e-10,
      "learning_rate": 0.00034476499999999997,
      "loss": 0.0,
      "step": 31100
    },
    {
      "epoch": 3.1184407796101947,
      "grad_norm": 9.138075296455384e-10,
      "learning_rate": 0.000344265,
      "loss": 0.0,
      "step": 31200
    },
    {
      "epoch": 3.1284357821089457,
      "grad_norm": 9.132489209306982e-10,
      "learning_rate": 0.000343765,
      "loss": 0.0,
      "step": 31300
    },
    {
      "epoch": 3.138430784607696,
      "grad_norm": 9.171791659490225e-10,
      "learning_rate": 0.000343265,
      "loss": 0.0,
      "step": 31400
    },
    {
      "epoch": 3.1484257871064467,
      "grad_norm": 9.165639358599265e-10,
      "learning_rate": 0.000342765,
      "loss": 0.0,
      "step": 31500
    },
    {
      "epoch": 3.1584207896051972,
      "grad_norm": 8.904997295111627e-10,
      "learning_rate": 0.000342265,
      "loss": 0.0,
      "step": 31600
    },
    {
      "epoch": 3.168415792103948,
      "grad_norm": 8.720854594024274e-10,
      "learning_rate": 0.000341765,
      "loss": 0.0,
      "step": 31700
    },
    {
      "epoch": 3.1784107946026987,
      "grad_norm": 8.937486861704258e-10,
      "learning_rate": 0.000341265,
      "loss": 0.0,
      "step": 31800
    },
    {
      "epoch": 3.1884057971014492,
      "grad_norm": 8.856469446705262e-10,
      "learning_rate": 0.000340765,
      "loss": 0.0,
      "step": 31900
    },
    {
      "epoch": 3.1984007996001997,
      "grad_norm": 8.908384030448246e-10,
      "learning_rate": 0.00034026499999999997,
      "loss": 0.0,
      "step": 32000
    },
    {
      "epoch": 3.2083958020989507,
      "grad_norm": 8.994108791071653e-10,
      "learning_rate": 0.000339765,
      "loss": 0.0,
      "step": 32100
    },
    {
      "epoch": 3.218390804597701,
      "grad_norm": 8.906307358280685e-10,
      "learning_rate": 0.000339265,
      "loss": 0.0,
      "step": 32200
    },
    {
      "epoch": 3.2283858070964517,
      "grad_norm": 8.986841826263969e-10,
      "learning_rate": 0.000338765,
      "loss": 0.0,
      "step": 32300
    },
    {
      "epoch": 3.2383808095952022,
      "grad_norm": 8.912066640220928e-10,
      "learning_rate": 0.000338265,
      "loss": 0.0,
      "step": 32400
    },
    {
      "epoch": 3.248375812093953,
      "grad_norm": 8.823894392939735e-10,
      "learning_rate": 0.00033776499999999996,
      "loss": 0.0,
      "step": 32500
    },
    {
      "epoch": 3.2583708145927037,
      "grad_norm": 8.867310219429214e-10,
      "learning_rate": 0.000337265,
      "loss": 0.0,
      "step": 32600
    },
    {
      "epoch": 3.2683658170914542,
      "grad_norm": 8.775027371399347e-10,
      "learning_rate": 0.000336765,
      "loss": 0.0,
      "step": 32700
    },
    {
      "epoch": 3.2783608195902048,
      "grad_norm": 8.847533261580054e-10,
      "learning_rate": 0.000336265,
      "loss": 0.0,
      "step": 32800
    },
    {
      "epoch": 3.2883558220889557,
      "grad_norm": 8.775508097969009e-10,
      "learning_rate": 0.00033576499999999997,
      "loss": 0.0,
      "step": 32900
    },
    {
      "epoch": 3.2983508245877062,
      "grad_norm": 8.83741690937967e-10,
      "learning_rate": 0.000335265,
      "loss": 0.0,
      "step": 33000
    },
    {
      "epoch": 3.3083458270864567,
      "grad_norm": 8.79228467809412e-10,
      "learning_rate": 0.000334765,
      "loss": 0.0,
      "step": 33100
    },
    {
      "epoch": 3.3183408295852073,
      "grad_norm": 8.856791966493915e-10,
      "learning_rate": 0.000334265,
      "loss": 0.0,
      "step": 33200
    },
    {
      "epoch": 3.3283358320839582,
      "grad_norm": 8.852780730705945e-10,
      "learning_rate": 0.000333765,
      "loss": 0.0,
      "step": 33300
    },
    {
      "epoch": 3.3383308345827087,
      "grad_norm": 8.719849842186989e-10,
      "learning_rate": 0.00033326499999999996,
      "loss": 0.0,
      "step": 33400
    },
    {
      "epoch": 3.3483258370814593,
      "grad_norm": 8.665558270948281e-10,
      "learning_rate": 0.000332765,
      "loss": 0.0,
      "step": 33500
    },
    {
      "epoch": 3.3583208395802098,
      "grad_norm": 8.623497471660357e-10,
      "learning_rate": 0.000332265,
      "loss": 0.0,
      "step": 33600
    },
    {
      "epoch": 3.3683158420789603,
      "grad_norm": 8.541877760670502e-10,
      "learning_rate": 0.000331765,
      "loss": 0.0,
      "step": 33700
    },
    {
      "epoch": 3.3783108445777112,
      "grad_norm": 8.659057915139101e-10,
      "learning_rate": 0.00033126499999999997,
      "loss": 0.0,
      "step": 33800
    },
    {
      "epoch": 3.3883058470764618,
      "grad_norm": 8.559523090312382e-10,
      "learning_rate": 0.000330765,
      "loss": 0.0,
      "step": 33900
    },
    {
      "epoch": 3.3983008495752123,
      "grad_norm": 8.657036754122771e-10,
      "learning_rate": 0.000330265,
      "loss": 0.0,
      "step": 34000
    },
    {
      "epoch": 3.4082958520739632,
      "grad_norm": 8.57241277962828e-10,
      "learning_rate": 0.000329765,
      "loss": 0.0,
      "step": 34100
    },
    {
      "epoch": 3.4182908545727138,
      "grad_norm": 8.673351481469638e-10,
      "learning_rate": 0.00032926499999999997,
      "loss": 0.0,
      "step": 34200
    },
    {
      "epoch": 3.4282858570714643,
      "grad_norm": 8.597270118038125e-10,
      "learning_rate": 0.00032876499999999996,
      "loss": 0.0,
      "step": 34300
    },
    {
      "epoch": 3.438280859570215,
      "grad_norm": 8.436474852047127e-10,
      "learning_rate": 0.000328265,
      "loss": 0.0,
      "step": 34400
    },
    {
      "epoch": 3.4482758620689653,
      "grad_norm": 8.4212259388039e-10,
      "learning_rate": 0.000327765,
      "loss": 0.0,
      "step": 34500
    },
    {
      "epoch": 3.4582708645677163,
      "grad_norm": 8.372781357124381e-10,
      "learning_rate": 0.000327265,
      "loss": 0.0,
      "step": 34600
    },
    {
      "epoch": 3.468265867066467,
      "grad_norm": 8.487468505791185e-10,
      "learning_rate": 0.000326765,
      "loss": 0.0,
      "step": 34700
    },
    {
      "epoch": 3.4782608695652173,
      "grad_norm": 8.351580538246139e-10,
      "learning_rate": 0.000326265,
      "loss": 0.0,
      "step": 34800
    },
    {
      "epoch": 3.4882558720639683,
      "grad_norm": 8.346942581560768e-10,
      "learning_rate": 0.00032576500000000005,
      "loss": 0.0,
      "step": 34900
    },
    {
      "epoch": 3.4982508745627188,
      "grad_norm": 8.341646817733306e-10,
      "learning_rate": 0.00032526500000000004,
      "loss": 0.0,
      "step": 35000
    },
    {
      "epoch": 3.5082458770614693,
      "grad_norm": 8.237439619307452e-10,
      "learning_rate": 0.000324765,
      "loss": 0.0,
      "step": 35100
    },
    {
      "epoch": 3.51824087956022,
      "grad_norm": 8.277198371153816e-10,
      "learning_rate": 0.000324265,
      "loss": 0.0,
      "step": 35200
    },
    {
      "epoch": 3.5282358820589703,
      "grad_norm": 8.235414017399023e-10,
      "learning_rate": 0.00032376500000000006,
      "loss": 0.0,
      "step": 35300
    },
    {
      "epoch": 3.5382308845577213,
      "grad_norm": 8.304027465655395e-10,
      "learning_rate": 0.00032326500000000004,
      "loss": 0.0,
      "step": 35400
    },
    {
      "epoch": 3.548225887056472,
      "grad_norm": 8.237175386227591e-10,
      "learning_rate": 0.00032276500000000003,
      "loss": 0.0,
      "step": 35500
    },
    {
      "epoch": 3.5582208895552223,
      "grad_norm": 8.156826325489419e-10,
      "learning_rate": 0.000322265,
      "loss": 0.0,
      "step": 35600
    },
    {
      "epoch": 3.5682158920539733,
      "grad_norm": 8.135314644164282e-10,
      "learning_rate": 0.000321765,
      "loss": 0.0,
      "step": 35700
    },
    {
      "epoch": 3.578210894552724,
      "grad_norm": 8.21238854697981e-10,
      "learning_rate": 0.00032126500000000005,
      "loss": 0.0,
      "step": 35800
    },
    {
      "epoch": 3.5882058970514743,
      "grad_norm": 8.144457885883583e-10,
      "learning_rate": 0.00032076500000000004,
      "loss": 0.0,
      "step": 35900
    },
    {
      "epoch": 3.598200899550225,
      "grad_norm": 8.148536845276055e-10,
      "learning_rate": 0.000320265,
      "loss": 0.0,
      "step": 36000
    },
    {
      "epoch": 3.6081959020489753,
      "grad_norm": 8.037575049968382e-10,
      "learning_rate": 0.000319765,
      "loss": 0.0,
      "step": 36100
    },
    {
      "epoch": 3.6181909045477263,
      "grad_norm": 8.068247736581213e-10,
      "learning_rate": 0.00031926500000000005,
      "loss": 0.0,
      "step": 36200
    },
    {
      "epoch": 3.628185907046477,
      "grad_norm": 7.675989843747288e-10,
      "learning_rate": 0.00031876500000000004,
      "loss": 0.0,
      "step": 36300
    },
    {
      "epoch": 3.6381809095452273,
      "grad_norm": 7.866767237629801e-10,
      "learning_rate": 0.00031826500000000003,
      "loss": 0.0,
      "step": 36400
    },
    {
      "epoch": 3.6481759120439783,
      "grad_norm": 7.98203170226941e-10,
      "learning_rate": 0.000317765,
      "loss": 0.0,
      "step": 36500
    },
    {
      "epoch": 3.658170914542729,
      "grad_norm": 7.796219780864533e-10,
      "learning_rate": 0.000317265,
      "loss": 0.0,
      "step": 36600
    },
    {
      "epoch": 3.6681659170414793,
      "grad_norm": 7.817526070930114e-10,
      "learning_rate": 0.00031676500000000005,
      "loss": 0.0,
      "step": 36700
    },
    {
      "epoch": 3.67816091954023,
      "grad_norm": 7.795307732649803e-10,
      "learning_rate": 0.00031626500000000004,
      "loss": 0.0,
      "step": 36800
    },
    {
      "epoch": 3.6881559220389803,
      "grad_norm": 7.900813892014469e-10,
      "learning_rate": 0.000315765,
      "loss": 0.0,
      "step": 36900
    },
    {
      "epoch": 3.698150924537731,
      "grad_norm": 7.729666906541866e-10,
      "learning_rate": 0.000315265,
      "loss": 0.0,
      "step": 37000
    },
    {
      "epoch": 3.708145927036482,
      "grad_norm": 7.649531563735934e-10,
      "learning_rate": 0.000314765,
      "loss": 0.0,
      "step": 37100
    },
    {
      "epoch": 3.7181409295352323,
      "grad_norm": 7.638842336454843e-10,
      "learning_rate": 0.00031426500000000004,
      "loss": 0.0,
      "step": 37200
    },
    {
      "epoch": 3.728135932033983,
      "grad_norm": 7.637254717529629e-10,
      "learning_rate": 0.00031376500000000003,
      "loss": 0.0,
      "step": 37300
    },
    {
      "epoch": 3.738130934532734,
      "grad_norm": 7.638374377449964e-10,
      "learning_rate": 0.000313265,
      "loss": 0.0,
      "step": 37400
    },
    {
      "epoch": 3.7481259370314843,
      "grad_norm": 7.655590605892826e-10,
      "learning_rate": 0.000312765,
      "loss": 0.0,
      "step": 37500
    },
    {
      "epoch": 3.758120939530235,
      "grad_norm": 7.553734304721615e-10,
      "learning_rate": 0.00031226500000000005,
      "loss": 0.0,
      "step": 37600
    },
    {
      "epoch": 3.7681159420289854,
      "grad_norm": 7.665830747960456e-10,
      "learning_rate": 0.00031176500000000003,
      "loss": 0.0,
      "step": 37700
    },
    {
      "epoch": 3.778110944527736,
      "grad_norm": 7.634018417412847e-10,
      "learning_rate": 0.000311265,
      "loss": 0.0,
      "step": 37800
    },
    {
      "epoch": 3.788105947026487,
      "grad_norm": 7.606719143460339e-10,
      "learning_rate": 0.000310765,
      "loss": 0.0,
      "step": 37900
    },
    {
      "epoch": 3.7981009495252374,
      "grad_norm": 7.612759311825812e-10,
      "learning_rate": 0.000310265,
      "loss": 0.0,
      "step": 38000
    },
    {
      "epoch": 3.808095952023988,
      "grad_norm": 7.752298247787337e-10,
      "learning_rate": 0.00030976500000000004,
      "loss": 0.0,
      "step": 38100
    },
    {
      "epoch": 3.818090954522739,
      "grad_norm": 7.521414602251753e-10,
      "learning_rate": 0.00030926500000000003,
      "loss": 0.0,
      "step": 38200
    },
    {
      "epoch": 3.8280859570214893,
      "grad_norm": 7.417921277230732e-10,
      "learning_rate": 0.000308765,
      "loss": 0.0,
      "step": 38300
    },
    {
      "epoch": 3.83808095952024,
      "grad_norm": 7.571508975345864e-10,
      "learning_rate": 0.000308265,
      "loss": 0.0,
      "step": 38400
    },
    {
      "epoch": 3.8480759620189904,
      "grad_norm": 7.453810901836277e-10,
      "learning_rate": 0.000307765,
      "loss": 0.0,
      "step": 38500
    },
    {
      "epoch": 3.858070964517741,
      "grad_norm": 7.268220469924813e-10,
      "learning_rate": 0.00030726500000000003,
      "loss": 0.0,
      "step": 38600
    },
    {
      "epoch": 3.868065967016492,
      "grad_norm": 7.295818393870945e-10,
      "learning_rate": 0.000306765,
      "loss": 0.0,
      "step": 38700
    },
    {
      "epoch": 3.8780609695152424,
      "grad_norm": 7.323764372735297e-10,
      "learning_rate": 0.000306265,
      "loss": 0.0,
      "step": 38800
    },
    {
      "epoch": 3.888055972013993,
      "grad_norm": 7.419386771623238e-10,
      "learning_rate": 0.000305765,
      "loss": 0.0,
      "step": 38900
    },
    {
      "epoch": 3.898050974512744,
      "grad_norm": 7.173039939800674e-10,
      "learning_rate": 0.00030526500000000004,
      "loss": 0.0,
      "step": 39000
    },
    {
      "epoch": 3.9080459770114944,
      "grad_norm": 7.270162249994883e-10,
      "learning_rate": 0.00030476500000000003,
      "loss": 0.0,
      "step": 39100
    },
    {
      "epoch": 3.918040979510245,
      "grad_norm": 7.249316147373008e-10,
      "learning_rate": 0.000304265,
      "loss": 0.0,
      "step": 39200
    },
    {
      "epoch": 3.9280359820089954,
      "grad_norm": 7.251491629389761e-10,
      "learning_rate": 0.000303765,
      "loss": 0.0,
      "step": 39300
    },
    {
      "epoch": 3.938030984507746,
      "grad_norm": 7.269861934666721e-10,
      "learning_rate": 0.000303265,
      "loss": 0.0,
      "step": 39400
    },
    {
      "epoch": 3.948025987006497,
      "grad_norm": 7.252288769521442e-10,
      "learning_rate": 0.00030276500000000003,
      "loss": 0.0,
      "step": 39500
    },
    {
      "epoch": 3.9580209895052474,
      "grad_norm": 7.352645159386384e-10,
      "learning_rate": 0.000302265,
      "loss": 0.0,
      "step": 39600
    },
    {
      "epoch": 3.968015992003998,
      "grad_norm": 7.230157583748564e-10,
      "learning_rate": 0.000301765,
      "loss": 0.0,
      "step": 39700
    },
    {
      "epoch": 3.978010994502749,
      "grad_norm": 7.261902190691671e-10,
      "learning_rate": 0.000301265,
      "loss": 0.0,
      "step": 39800
    },
    {
      "epoch": 3.9880059970014994,
      "grad_norm": 7.135227408916478e-10,
      "learning_rate": 0.000300765,
      "loss": 0.0,
      "step": 39900
    },
    {
      "epoch": 3.99800099950025,
      "grad_norm": 7.107620603186149e-10,
      "learning_rate": 0.000300265,
      "loss": 0.0,
      "step": 40000
    },
    {
      "epoch": 4.007996001999,
      "grad_norm": 6.915821249009468e-10,
      "learning_rate": 0.000299765,
      "loss": 0.0,
      "step": 40100
    },
    {
      "epoch": 4.017991004497751,
      "grad_norm": 7.134330348712581e-10,
      "learning_rate": 0.000299265,
      "loss": 0.0,
      "step": 40200
    },
    {
      "epoch": 4.0279860069965014,
      "grad_norm": 7.065042439968749e-10,
      "learning_rate": 0.000298765,
      "loss": 0.0,
      "step": 40300
    },
    {
      "epoch": 4.037981009495252,
      "grad_norm": 7.199473794905487e-10,
      "learning_rate": 0.00029826500000000003,
      "loss": 0.0,
      "step": 40400
    },
    {
      "epoch": 4.047976011994003,
      "grad_norm": 7.034325899546445e-10,
      "learning_rate": 0.000297765,
      "loss": 0.0,
      "step": 40500
    },
    {
      "epoch": 4.057971014492754,
      "grad_norm": 6.966162646726559e-10,
      "learning_rate": 0.000297265,
      "loss": 0.0,
      "step": 40600
    },
    {
      "epoch": 4.067966016991504,
      "grad_norm": 6.906820670948832e-10,
      "learning_rate": 0.000296765,
      "loss": 0.0,
      "step": 40700
    },
    {
      "epoch": 4.077961019490255,
      "grad_norm": 6.940941155164637e-10,
      "learning_rate": 0.000296265,
      "loss": 0.0,
      "step": 40800
    },
    {
      "epoch": 4.087956021989005,
      "grad_norm": 7.093881593256413e-10,
      "learning_rate": 0.000295765,
      "loss": 0.0,
      "step": 40900
    },
    {
      "epoch": 4.097951024487756,
      "grad_norm": 7.010640401539092e-10,
      "learning_rate": 0.000295265,
      "loss": 0.0,
      "step": 41000
    },
    {
      "epoch": 4.1079460269865065,
      "grad_norm": 6.927085016705803e-10,
      "learning_rate": 0.000294765,
      "loss": 0.0,
      "step": 41100
    },
    {
      "epoch": 4.117941029485257,
      "grad_norm": 7.003964075380509e-10,
      "learning_rate": 0.000294265,
      "loss": 0.0,
      "step": 41200
    },
    {
      "epoch": 4.127936031984008,
      "grad_norm": 6.796850859913661e-10,
      "learning_rate": 0.00029376500000000003,
      "loss": 0.0,
      "step": 41300
    },
    {
      "epoch": 4.137931034482759,
      "grad_norm": 6.7896660516098e-10,
      "learning_rate": 0.000293265,
      "loss": 0.0,
      "step": 41400
    },
    {
      "epoch": 4.147926036981509,
      "grad_norm": 6.936069496532582e-10,
      "learning_rate": 0.000292765,
      "loss": 0.0,
      "step": 41500
    },
    {
      "epoch": 4.15792103948026,
      "grad_norm": 6.85189183169399e-10,
      "learning_rate": 0.000292265,
      "loss": 0.0,
      "step": 41600
    },
    {
      "epoch": 4.1679160419790104,
      "grad_norm": 6.77534306436911e-10,
      "learning_rate": 0.000291765,
      "loss": 0.0,
      "step": 41700
    },
    {
      "epoch": 4.177911044477761,
      "grad_norm": 6.774185101754426e-10,
      "learning_rate": 0.000291265,
      "loss": 0.0,
      "step": 41800
    },
    {
      "epoch": 4.1879060469765115,
      "grad_norm": 6.789863671308183e-10,
      "learning_rate": 0.000290765,
      "loss": 0.0,
      "step": 41900
    },
    {
      "epoch": 4.197901049475262,
      "grad_norm": 6.712084221760506e-10,
      "learning_rate": 0.000290265,
      "loss": 0.0,
      "step": 42000
    },
    {
      "epoch": 4.207896051974013,
      "grad_norm": 6.721450063196244e-10,
      "learning_rate": 0.000289765,
      "loss": 0.0,
      "step": 42100
    },
    {
      "epoch": 4.217891054472764,
      "grad_norm": 6.698945287375579e-10,
      "learning_rate": 0.000289265,
      "loss": 0.0,
      "step": 42200
    },
    {
      "epoch": 4.227886056971514,
      "grad_norm": 6.791074924628049e-10,
      "learning_rate": 0.000288765,
      "loss": 0.0,
      "step": 42300
    },
    {
      "epoch": 4.237881059470265,
      "grad_norm": 6.768817173430364e-10,
      "learning_rate": 0.000288265,
      "loss": 0.0,
      "step": 42400
    },
    {
      "epoch": 4.2478760619690155,
      "grad_norm": 6.67850608149223e-10,
      "learning_rate": 0.000287765,
      "loss": 0.0,
      "step": 42500
    },
    {
      "epoch": 4.257871064467766,
      "grad_norm": 6.659984785883921e-10,
      "learning_rate": 0.000287265,
      "loss": 0.0,
      "step": 42600
    },
    {
      "epoch": 4.2678660669665165,
      "grad_norm": 6.622064563366337e-10,
      "learning_rate": 0.000286765,
      "loss": 0.0,
      "step": 42700
    },
    {
      "epoch": 4.277861069465267,
      "grad_norm": 6.778901884274546e-10,
      "learning_rate": 0.000286265,
      "loss": 0.0,
      "step": 42800
    },
    {
      "epoch": 4.287856071964018,
      "grad_norm": 6.701401655817563e-10,
      "learning_rate": 0.000285765,
      "loss": 0.0,
      "step": 42900
    },
    {
      "epoch": 4.297851074462769,
      "grad_norm": 6.654863327071325e-10,
      "learning_rate": 0.000285265,
      "loss": 0.0,
      "step": 43000
    },
    {
      "epoch": 4.307846076961519,
      "grad_norm": 6.603753099909682e-10,
      "learning_rate": 0.000284765,
      "loss": 0.0,
      "step": 43100
    },
    {
      "epoch": 4.31784107946027,
      "grad_norm": 6.504345950730794e-10,
      "learning_rate": 0.000284265,
      "loss": 0.0,
      "step": 43200
    },
    {
      "epoch": 4.3278360819590205,
      "grad_norm": 6.629544690994749e-10,
      "learning_rate": 0.000283765,
      "loss": 0.0,
      "step": 43300
    },
    {
      "epoch": 4.337831084457771,
      "grad_norm": 6.647605799159351e-10,
      "learning_rate": 0.000283265,
      "loss": 0.0,
      "step": 43400
    },
    {
      "epoch": 4.3478260869565215,
      "grad_norm": 6.460509349714982e-10,
      "learning_rate": 0.000282765,
      "loss": 0.0,
      "step": 43500
    },
    {
      "epoch": 4.357821089455272,
      "grad_norm": 6.450919798339783e-10,
      "learning_rate": 0.00028226499999999997,
      "loss": 0.0,
      "step": 43600
    },
    {
      "epoch": 4.3678160919540225,
      "grad_norm": 6.453336198752879e-10,
      "learning_rate": 0.000281765,
      "loss": 0.0,
      "step": 43700
    },
    {
      "epoch": 4.377811094452774,
      "grad_norm": 6.406640773448657e-10,
      "learning_rate": 0.000281265,
      "loss": 0.0,
      "step": 43800
    },
    {
      "epoch": 4.3878060969515245,
      "grad_norm": 6.496919113807564e-10,
      "learning_rate": 0.000280765,
      "loss": 0.0,
      "step": 43900
    },
    {
      "epoch": 4.397801099450275,
      "grad_norm": 6.624084614159642e-10,
      "learning_rate": 0.000280265,
      "loss": 0.0,
      "step": 44000
    },
    {
      "epoch": 4.4077961019490255,
      "grad_norm": 6.552679510107851e-10,
      "learning_rate": 0.000279765,
      "loss": 0.0,
      "step": 44100
    },
    {
      "epoch": 4.417791104447776,
      "grad_norm": 6.596286850069077e-10,
      "learning_rate": 0.000279265,
      "loss": 0.0,
      "step": 44200
    },
    {
      "epoch": 4.4277861069465265,
      "grad_norm": 6.481185588214089e-10,
      "learning_rate": 0.000278765,
      "loss": 0.0,
      "step": 44300
    },
    {
      "epoch": 4.437781109445277,
      "grad_norm": 6.479293213068615e-10,
      "learning_rate": 0.000278265,
      "loss": 0.0,
      "step": 44400
    },
    {
      "epoch": 4.447776111944028,
      "grad_norm": 6.520082251881831e-10,
      "learning_rate": 0.00027776499999999997,
      "loss": 0.0,
      "step": 44500
    },
    {
      "epoch": 4.457771114442779,
      "grad_norm": 6.479684011573283e-10,
      "learning_rate": 0.000277265,
      "loss": 0.0,
      "step": 44600
    },
    {
      "epoch": 4.4677661169415295,
      "grad_norm": 6.431241095228302e-10,
      "learning_rate": 0.000276765,
      "loss": 0.0,
      "step": 44700
    },
    {
      "epoch": 4.47776111944028,
      "grad_norm": 6.435047494868229e-10,
      "learning_rate": 0.000276265,
      "loss": 0.0,
      "step": 44800
    },
    {
      "epoch": 4.4877561219390305,
      "grad_norm": 6.577081101966087e-10,
      "learning_rate": 0.00027576499999999997,
      "loss": 0.0,
      "step": 44900
    },
    {
      "epoch": 4.497751124437781,
      "grad_norm": 6.205086444666108e-10,
      "learning_rate": 0.00027526499999999996,
      "loss": 0.0,
      "step": 45000
    },
    {
      "epoch": 4.5077461269365315,
      "grad_norm": 6.527157148106255e-10,
      "learning_rate": 0.000274765,
      "loss": 0.0,
      "step": 45100
    },
    {
      "epoch": 4.517741129435282,
      "grad_norm": 6.527610674211815e-10,
      "learning_rate": 0.000274265,
      "loss": 0.0,
      "step": 45200
    },
    {
      "epoch": 4.527736131934033,
      "grad_norm": 6.374294425626204e-10,
      "learning_rate": 0.000273765,
      "loss": 0.0,
      "step": 45300
    },
    {
      "epoch": 4.537731134432784,
      "grad_norm": 6.304979316418269e-10,
      "learning_rate": 0.00027326499999999997,
      "loss": 0.0,
      "step": 45400
    },
    {
      "epoch": 4.5477261369315345,
      "grad_norm": 6.419500486742891e-10,
      "learning_rate": 0.000272765,
      "loss": 0.0,
      "step": 45500
    },
    {
      "epoch": 4.557721139430285,
      "grad_norm": 6.42680964002551e-10,
      "learning_rate": 0.000272265,
      "loss": 0.0,
      "step": 45600
    },
    {
      "epoch": 4.5677161419290355,
      "grad_norm": 6.381286610235293e-10,
      "learning_rate": 0.000271765,
      "loss": 0.0,
      "step": 45700
    },
    {
      "epoch": 4.577711144427786,
      "grad_norm": 6.389660467398528e-10,
      "learning_rate": 0.00027126499999999997,
      "loss": 0.0,
      "step": 45800
    },
    {
      "epoch": 4.5877061469265366,
      "grad_norm": 6.306454247706483e-10,
      "learning_rate": 0.00027076499999999996,
      "loss": 0.0,
      "step": 45900
    },
    {
      "epoch": 4.597701149425287,
      "grad_norm": 6.263751184398814e-10,
      "learning_rate": 0.000270265,
      "loss": 0.0,
      "step": 46000
    },
    {
      "epoch": 4.6076961519240385,
      "grad_norm": 6.425864285120042e-10,
      "learning_rate": 0.000269765,
      "loss": 0.0,
      "step": 46100
    },
    {
      "epoch": 4.617691154422789,
      "grad_norm": 6.33925245629996e-10,
      "learning_rate": 0.000269265,
      "loss": 0.0,
      "step": 46200
    },
    {
      "epoch": 4.6276861569215395,
      "grad_norm": 6.440039057586944e-10,
      "learning_rate": 0.00026876499999999997,
      "loss": 0.0,
      "step": 46300
    },
    {
      "epoch": 4.63768115942029,
      "grad_norm": 6.243688344120812e-10,
      "learning_rate": 0.000268265,
      "loss": 0.0,
      "step": 46400
    },
    {
      "epoch": 4.6476761619190405,
      "grad_norm": 6.155335130486606e-10,
      "learning_rate": 0.000267765,
      "loss": 0.0,
      "step": 46500
    },
    {
      "epoch": 4.657671164417791,
      "grad_norm": 6.298888077793663e-10,
      "learning_rate": 0.000267265,
      "loss": 0.0,
      "step": 46600
    },
    {
      "epoch": 4.667666166916542,
      "grad_norm": 6.276091868429035e-10,
      "learning_rate": 0.00026676499999999997,
      "loss": 0.0,
      "step": 46700
    },
    {
      "epoch": 4.677661169415292,
      "grad_norm": 6.205767011380203e-10,
      "learning_rate": 0.00026626499999999996,
      "loss": 0.0,
      "step": 46800
    },
    {
      "epoch": 4.687656171914043,
      "grad_norm": 6.206512526141239e-10,
      "learning_rate": 0.000265765,
      "loss": 0.0,
      "step": 46900
    },
    {
      "epoch": 4.697651174412794,
      "grad_norm": 6.328348400863604e-10,
      "learning_rate": 0.000265265,
      "loss": 0.0,
      "step": 47000
    },
    {
      "epoch": 4.7076461769115445,
      "grad_norm": 6.143611175346564e-10,
      "learning_rate": 0.000264765,
      "loss": 0.0,
      "step": 47100
    },
    {
      "epoch": 4.717641179410295,
      "grad_norm": 6.287767528867505e-10,
      "learning_rate": 0.000264265,
      "loss": 0.0,
      "step": 47200
    },
    {
      "epoch": 4.7276361819090456,
      "grad_norm": 6.133840102506838e-10,
      "learning_rate": 0.000263765,
      "loss": 0.0,
      "step": 47300
    },
    {
      "epoch": 4.737631184407796,
      "grad_norm": 6.336153823838231e-10,
      "learning_rate": 0.00026326500000000005,
      "loss": 0.0,
      "step": 47400
    },
    {
      "epoch": 4.747626186906547,
      "grad_norm": 6.133632490801233e-10,
      "learning_rate": 0.00026276500000000004,
      "loss": 0.0,
      "step": 47500
    },
    {
      "epoch": 4.757621189405297,
      "grad_norm": 6.210794101235706e-10,
      "learning_rate": 0.000262265,
      "loss": 0.0,
      "step": 47600
    },
    {
      "epoch": 4.767616191904048,
      "grad_norm": 6.318380818548519e-10,
      "learning_rate": 0.000261765,
      "loss": 0.0,
      "step": 47700
    },
    {
      "epoch": 4.777611194402798,
      "grad_norm": 6.225314708174778e-10,
      "learning_rate": 0.00026126500000000005,
      "loss": 0.0,
      "step": 47800
    },
    {
      "epoch": 4.7876061969015495,
      "grad_norm": 6.127588991766686e-10,
      "learning_rate": 0.00026076500000000004,
      "loss": 0.0,
      "step": 47900
    },
    {
      "epoch": 4.7976011994003,
      "grad_norm": 6.132567231809105e-10,
      "learning_rate": 0.00026026500000000003,
      "loss": 0.0,
      "step": 48000
    },
    {
      "epoch": 4.807596201899051,
      "grad_norm": 6.126477658519036e-10,
      "learning_rate": 0.000259765,
      "loss": 0.0,
      "step": 48100
    },
    {
      "epoch": 4.817591204397801,
      "grad_norm": 6.209137093371453e-10,
      "learning_rate": 0.000259265,
      "loss": 0.0,
      "step": 48200
    },
    {
      "epoch": 4.827586206896552,
      "grad_norm": 6.195565727118435e-10,
      "learning_rate": 0.00025876500000000005,
      "loss": 0.0,
      "step": 48300
    },
    {
      "epoch": 4.837581209395302,
      "grad_norm": 6.117882311862388e-10,
      "learning_rate": 0.00025826500000000004,
      "loss": 0.0,
      "step": 48400
    },
    {
      "epoch": 4.847576211894053,
      "grad_norm": 6.204450286872998e-10,
      "learning_rate": 0.000257765,
      "loss": 0.0,
      "step": 48500
    },
    {
      "epoch": 4.857571214392804,
      "grad_norm": 6.076788516828913e-10,
      "learning_rate": 0.000257265,
      "loss": 0.0,
      "step": 48600
    },
    {
      "epoch": 4.8675662168915546,
      "grad_norm": 6.186477441438853e-10,
      "learning_rate": 0.00025676500000000005,
      "loss": 0.0,
      "step": 48700
    },
    {
      "epoch": 4.877561219390305,
      "grad_norm": 6.054651224829399e-10,
      "learning_rate": 0.00025626500000000004,
      "loss": 0.0,
      "step": 48800
    },
    {
      "epoch": 4.887556221889056,
      "grad_norm": 6.119790785241719e-10,
      "learning_rate": 0.00025576500000000003,
      "loss": 0.0,
      "step": 48900
    },
    {
      "epoch": 4.897551224387806,
      "grad_norm": 6.119293960438199e-10,
      "learning_rate": 0.000255265,
      "loss": 0.0,
      "step": 49000
    },
    {
      "epoch": 4.907546226886557,
      "grad_norm": 6.162482746319142e-10,
      "learning_rate": 0.000254765,
      "loss": 0.0,
      "step": 49100
    },
    {
      "epoch": 4.917541229385307,
      "grad_norm": 6.064995172749832e-10,
      "learning_rate": 0.00025426500000000005,
      "loss": 0.0,
      "step": 49200
    },
    {
      "epoch": 4.927536231884058,
      "grad_norm": 6.214468939447215e-10,
      "learning_rate": 0.00025376500000000003,
      "loss": 0.0,
      "step": 49300
    },
    {
      "epoch": 4.937531234382808,
      "grad_norm": 6.127904295105679e-10,
      "learning_rate": 0.000253265,
      "loss": 0.0,
      "step": 49400
    },
    {
      "epoch": 4.94752623688156,
      "grad_norm": 6.124049045652669e-10,
      "learning_rate": 0.000252765,
      "loss": 0.0,
      "step": 49500
    },
    {
      "epoch": 4.95752123938031,
      "grad_norm": 6.125996931949373e-10,
      "learning_rate": 0.000252265,
      "loss": 0.0,
      "step": 49600
    },
    {
      "epoch": 4.967516241879061,
      "grad_norm": 6.026454890672994e-10,
      "learning_rate": 0.00025176500000000004,
      "loss": 0.0,
      "step": 49700
    },
    {
      "epoch": 4.977511244377811,
      "grad_norm": 6.153771381356421e-10,
      "learning_rate": 0.00025126500000000003,
      "loss": 0.0,
      "step": 49800
    },
    {
      "epoch": 4.987506246876562,
      "grad_norm": 5.950933079645893e-10,
      "learning_rate": 0.000250765,
      "loss": 0.0,
      "step": 49900
    },
    {
      "epoch": 4.997501249375312,
      "grad_norm": 5.947897729896567e-10,
      "learning_rate": 0.000250265,
      "loss": 0.0,
      "step": 50000
    },
    {
      "epoch": 5.007496251874063,
      "grad_norm": 6.018924803008474e-10,
      "learning_rate": 0.000249765,
      "loss": 0.0,
      "step": 50100
    },
    {
      "epoch": 5.017491254372813,
      "grad_norm": 6.080252412665743e-10,
      "learning_rate": 0.000249265,
      "loss": 0.0,
      "step": 50200
    },
    {
      "epoch": 5.027486256871565,
      "grad_norm": 6.070617897258046e-10,
      "learning_rate": 0.00024876499999999997,
      "loss": 0.0,
      "step": 50300
    },
    {
      "epoch": 5.037481259370315,
      "grad_norm": 5.957119797450616e-10,
      "learning_rate": 0.000248265,
      "loss": 0.0,
      "step": 50400
    },
    {
      "epoch": 5.047476261869066,
      "grad_norm": 6.079436953854156e-10,
      "learning_rate": 0.000247765,
      "loss": 0.0,
      "step": 50500
    },
    {
      "epoch": 5.057471264367816,
      "grad_norm": 6.04891692290721e-10,
      "learning_rate": 0.00024726500000000004,
      "loss": 0.0,
      "step": 50600
    },
    {
      "epoch": 5.067466266866567,
      "grad_norm": 6.062476076706957e-10,
      "learning_rate": 0.000246765,
      "loss": 0.0,
      "step": 50700
    },
    {
      "epoch": 5.077461269365317,
      "grad_norm": 6.075105973835093e-10,
      "learning_rate": 0.000246265,
      "loss": 0.0,
      "step": 50800
    },
    {
      "epoch": 5.087456271864068,
      "grad_norm": 5.964330695995557e-10,
      "learning_rate": 0.000245765,
      "loss": 0.0,
      "step": 50900
    },
    {
      "epoch": 5.097451274362818,
      "grad_norm": 6.034129862442228e-10,
      "learning_rate": 0.000245265,
      "loss": 0.0,
      "step": 51000
    },
    {
      "epoch": 5.10744627686157,
      "grad_norm": 6.071488867220864e-10,
      "learning_rate": 0.00024476500000000003,
      "loss": 0.0,
      "step": 51100
    },
    {
      "epoch": 5.11744127936032,
      "grad_norm": 6.076625869155805e-10,
      "learning_rate": 0.000244265,
      "loss": 0.0,
      "step": 51200
    },
    {
      "epoch": 5.127436281859071,
      "grad_norm": 5.951804604720223e-10,
      "learning_rate": 0.000243765,
      "loss": 0.0,
      "step": 51300
    },
    {
      "epoch": 5.137431284357821,
      "grad_norm": 6.047323752866873e-10,
      "learning_rate": 0.00024326500000000002,
      "loss": 0.0,
      "step": 51400
    },
    {
      "epoch": 5.147426286856572,
      "grad_norm": 5.949234993529728e-10,
      "learning_rate": 0.000242765,
      "loss": 0.0,
      "step": 51500
    },
    {
      "epoch": 5.157421289355322,
      "grad_norm": 6.043202604999465e-10,
      "learning_rate": 0.00024226500000000003,
      "loss": 0.0,
      "step": 51600
    },
    {
      "epoch": 5.167416291854073,
      "grad_norm": 5.857585527735409e-10,
      "learning_rate": 0.00024176500000000001,
      "loss": 0.0,
      "step": 51700
    },
    {
      "epoch": 5.177411294352823,
      "grad_norm": 5.969635896718728e-10,
      "learning_rate": 0.000241265,
      "loss": 0.0,
      "step": 51800
    },
    {
      "epoch": 5.187406296851575,
      "grad_norm": 5.855446683078469e-10,
      "learning_rate": 0.00024076500000000002,
      "loss": 0.0,
      "step": 51900
    },
    {
      "epoch": 5.197401299350325,
      "grad_norm": 5.878590947361317e-10,
      "learning_rate": 0.000240265,
      "loss": 0.0,
      "step": 52000
    },
    {
      "epoch": 5.207396301849076,
      "grad_norm": 5.83865622516555e-10,
      "learning_rate": 0.00023976500000000002,
      "loss": 0.0,
      "step": 52100
    },
    {
      "epoch": 5.217391304347826,
      "grad_norm": 5.853745266293231e-10,
      "learning_rate": 0.000239265,
      "loss": 0.0,
      "step": 52200
    },
    {
      "epoch": 5.227386306846577,
      "grad_norm": 6.00081040413869e-10,
      "learning_rate": 0.00023876500000000002,
      "loss": 0.0,
      "step": 52300
    },
    {
      "epoch": 5.237381309345327,
      "grad_norm": 5.886027776291769e-10,
      "learning_rate": 0.000238265,
      "loss": 0.0,
      "step": 52400
    },
    {
      "epoch": 5.247376311844078,
      "grad_norm": 5.998490593128736e-10,
      "learning_rate": 0.000237765,
      "loss": 0.0,
      "step": 52500
    },
    {
      "epoch": 5.257371314342828,
      "grad_norm": 5.817225035009699e-10,
      "learning_rate": 0.000237265,
      "loss": 0.0,
      "step": 52600
    },
    {
      "epoch": 5.26736631684158,
      "grad_norm": 5.902081601227849e-10,
      "learning_rate": 0.000236765,
      "loss": 0.0,
      "step": 52700
    },
    {
      "epoch": 5.27736131934033,
      "grad_norm": 5.843682759909541e-10,
      "learning_rate": 0.00023626500000000002,
      "loss": 0.0,
      "step": 52800
    },
    {
      "epoch": 5.287356321839081,
      "grad_norm": 5.841295225295084e-10,
      "learning_rate": 0.000235765,
      "loss": 0.0,
      "step": 52900
    },
    {
      "epoch": 5.297351324337831,
      "grad_norm": 5.965414828779103e-10,
      "learning_rate": 0.00023526500000000002,
      "loss": 0.0,
      "step": 53000
    },
    {
      "epoch": 5.307346326836582,
      "grad_norm": 6.003007535504423e-10,
      "learning_rate": 0.000234765,
      "loss": 0.0,
      "step": 53100
    },
    {
      "epoch": 5.317341329335332,
      "grad_norm": 5.854922657810846e-10,
      "learning_rate": 0.000234265,
      "loss": 0.0,
      "step": 53200
    },
    {
      "epoch": 5.327336331834083,
      "grad_norm": 5.924726820261128e-10,
      "learning_rate": 0.000233765,
      "loss": 0.0,
      "step": 53300
    },
    {
      "epoch": 5.337331334332833,
      "grad_norm": 5.770262045956542e-10,
      "learning_rate": 0.000233265,
      "loss": 0.0,
      "step": 53400
    },
    {
      "epoch": 5.347326336831584,
      "grad_norm": 5.795798285745946e-10,
      "learning_rate": 0.000232765,
      "loss": 0.0,
      "step": 53500
    },
    {
      "epoch": 5.357321339330335,
      "grad_norm": 5.881911069316459e-10,
      "learning_rate": 0.000232265,
      "loss": 0.0,
      "step": 53600
    },
    {
      "epoch": 5.367316341829086,
      "grad_norm": 5.947057291066926e-10,
      "learning_rate": 0.00023176500000000001,
      "loss": 0.0,
      "step": 53700
    },
    {
      "epoch": 5.377311344327836,
      "grad_norm": 5.779989820098308e-10,
      "learning_rate": 0.000231265,
      "loss": 0.0,
      "step": 53800
    },
    {
      "epoch": 5.387306346826587,
      "grad_norm": 6.012190190141098e-10,
      "learning_rate": 0.000230765,
      "loss": 0.0,
      "step": 53900
    },
    {
      "epoch": 5.397301349325337,
      "grad_norm": 5.920491874533695e-10,
      "learning_rate": 0.000230265,
      "loss": 0.0,
      "step": 54000
    },
    {
      "epoch": 5.407296351824088,
      "grad_norm": 5.778548750612345e-10,
      "learning_rate": 0.000229765,
      "loss": 0.0,
      "step": 54100
    },
    {
      "epoch": 5.417291354322838,
      "grad_norm": 5.808196146261935e-10,
      "learning_rate": 0.000229265,
      "loss": 0.0,
      "step": 54200
    },
    {
      "epoch": 5.42728635682159,
      "grad_norm": 5.712652573208743e-10,
      "learning_rate": 0.000228765,
      "loss": 0.0,
      "step": 54300
    },
    {
      "epoch": 5.43728135932034,
      "grad_norm": 5.934301938737008e-10,
      "learning_rate": 0.000228265,
      "loss": 0.0,
      "step": 54400
    },
    {
      "epoch": 5.447276361819091,
      "grad_norm": 5.928855184578197e-10,
      "learning_rate": 0.000227765,
      "loss": 0.0,
      "step": 54500
    },
    {
      "epoch": 5.457271364317841,
      "grad_norm": 5.804639546802548e-10,
      "learning_rate": 0.000227265,
      "loss": 0.0,
      "step": 54600
    },
    {
      "epoch": 5.467266366816592,
      "grad_norm": 5.803397207237992e-10,
      "learning_rate": 0.000226765,
      "loss": 0.0,
      "step": 54700
    },
    {
      "epoch": 5.477261369315342,
      "grad_norm": 5.847362594124661e-10,
      "learning_rate": 0.000226265,
      "loss": 0.0,
      "step": 54800
    },
    {
      "epoch": 5.487256371814093,
      "grad_norm": 5.777317513278035e-10,
      "learning_rate": 0.000225765,
      "loss": 0.0,
      "step": 54900
    },
    {
      "epoch": 5.497251374312843,
      "grad_norm": 5.927766055791039e-10,
      "learning_rate": 0.000225265,
      "loss": 0.0,
      "step": 55000
    },
    {
      "epoch": 5.507246376811594,
      "grad_norm": 5.75965886095986e-10,
      "learning_rate": 0.000224765,
      "loss": 0.0,
      "step": 55100
    },
    {
      "epoch": 5.517241379310345,
      "grad_norm": 5.826631954697348e-10,
      "learning_rate": 0.000224265,
      "loss": 0.0,
      "step": 55200
    },
    {
      "epoch": 5.527236381809096,
      "grad_norm": 5.772969324802091e-10,
      "learning_rate": 0.00022376499999999998,
      "loss": 0.0,
      "step": 55300
    },
    {
      "epoch": 5.537231384307846,
      "grad_norm": 5.928195156990057e-10,
      "learning_rate": 0.000223265,
      "loss": 0.0,
      "step": 55400
    },
    {
      "epoch": 5.547226386806597,
      "grad_norm": 5.674619663054159e-10,
      "learning_rate": 0.00022276499999999999,
      "loss": 0.0,
      "step": 55500
    },
    {
      "epoch": 5.557221389305347,
      "grad_norm": 5.869260077950855e-10,
      "learning_rate": 0.000222265,
      "loss": 0.0,
      "step": 55600
    },
    {
      "epoch": 5.567216391804098,
      "grad_norm": 5.790556367735178e-10,
      "learning_rate": 0.000221765,
      "loss": 0.0,
      "step": 55700
    },
    {
      "epoch": 5.577211394302848,
      "grad_norm": 5.728942875649068e-10,
      "learning_rate": 0.000221265,
      "loss": 0.0,
      "step": 55800
    },
    {
      "epoch": 5.5872063968016,
      "grad_norm": 5.830099736314764e-10,
      "learning_rate": 0.000220765,
      "loss": 0.0,
      "step": 55900
    },
    {
      "epoch": 5.59720139930035,
      "grad_norm": 5.751993326086335e-10,
      "learning_rate": 0.000220265,
      "loss": 0.0,
      "step": 56000
    },
    {
      "epoch": 5.607196401799101,
      "grad_norm": 5.764162480659252e-10,
      "learning_rate": 0.000219765,
      "loss": 0.0,
      "step": 56100
    },
    {
      "epoch": 5.617191404297851,
      "grad_norm": 5.725704355086236e-10,
      "learning_rate": 0.00021926499999999998,
      "loss": 0.0,
      "step": 56200
    },
    {
      "epoch": 5.627186406796602,
      "grad_norm": 5.857779816764719e-10,
      "learning_rate": 0.000218765,
      "loss": 0.0,
      "step": 56300
    },
    {
      "epoch": 5.637181409295352,
      "grad_norm": 5.872665687078893e-10,
      "learning_rate": 0.00021826499999999998,
      "loss": 0.0,
      "step": 56400
    },
    {
      "epoch": 5.647176411794103,
      "grad_norm": 5.773202471637262e-10,
      "learning_rate": 0.000217765,
      "loss": 0.0,
      "step": 56500
    },
    {
      "epoch": 5.657171414292853,
      "grad_norm": 5.95763438582253e-10,
      "learning_rate": 0.00021726500000000001,
      "loss": 0.0,
      "step": 56600
    },
    {
      "epoch": 5.667166416791604,
      "grad_norm": 5.801381042225273e-10,
      "learning_rate": 0.00021676500000000003,
      "loss": 0.0,
      "step": 56700
    },
    {
      "epoch": 5.677161419290355,
      "grad_norm": 5.724380969240883e-10,
      "learning_rate": 0.00021626500000000002,
      "loss": 0.0,
      "step": 56800
    },
    {
      "epoch": 5.687156421789106,
      "grad_norm": 5.756470855544649e-10,
      "learning_rate": 0.000215765,
      "loss": 0.0,
      "step": 56900
    },
    {
      "epoch": 5.697151424287856,
      "grad_norm": 5.638856603873421e-10,
      "learning_rate": 0.00021526500000000002,
      "loss": 0.0,
      "step": 57000
    },
    {
      "epoch": 5.707146426786607,
      "grad_norm": 5.857992979585447e-10,
      "learning_rate": 0.000214765,
      "loss": 0.0,
      "step": 57100
    },
    {
      "epoch": 5.717141429285357,
      "grad_norm": 5.766014887775839e-10,
      "learning_rate": 0.00021426500000000002,
      "loss": 0.0,
      "step": 57200
    },
    {
      "epoch": 5.727136431784108,
      "grad_norm": 5.696512150876742e-10,
      "learning_rate": 0.000213765,
      "loss": 0.0,
      "step": 57300
    },
    {
      "epoch": 5.737131434282858,
      "grad_norm": 5.76346359526525e-10,
      "learning_rate": 0.00021326500000000003,
      "loss": 0.0,
      "step": 57400
    },
    {
      "epoch": 5.747126436781609,
      "grad_norm": 5.820081083740547e-10,
      "learning_rate": 0.00021276500000000001,
      "loss": 0.0,
      "step": 57500
    },
    {
      "epoch": 5.757121439280359,
      "grad_norm": 5.736562891378583e-10,
      "learning_rate": 0.000212265,
      "loss": 0.0,
      "step": 57600
    },
    {
      "epoch": 5.767116441779111,
      "grad_norm": 5.842669126288058e-10,
      "learning_rate": 0.00021176500000000002,
      "loss": 0.0,
      "step": 57700
    },
    {
      "epoch": 5.777111444277861,
      "grad_norm": 5.596439978106105e-10,
      "learning_rate": 0.000211265,
      "loss": 0.0,
      "step": 57800
    },
    {
      "epoch": 5.787106446776612,
      "grad_norm": 5.64876756481425e-10,
      "learning_rate": 0.00021076500000000002,
      "loss": 0.0,
      "step": 57900
    },
    {
      "epoch": 5.797101449275362,
      "grad_norm": 5.700336869196576e-10,
      "learning_rate": 0.000210265,
      "loss": 0.0,
      "step": 58000
    },
    {
      "epoch": 5.807096451774113,
      "grad_norm": 5.768509558912172e-10,
      "learning_rate": 0.00020976500000000002,
      "loss": 0.0,
      "step": 58100
    },
    {
      "epoch": 5.817091454272863,
      "grad_norm": 5.675681036265701e-10,
      "learning_rate": 0.000209265,
      "loss": 0.0,
      "step": 58200
    },
    {
      "epoch": 5.827086456771614,
      "grad_norm": 5.866579444457898e-10,
      "learning_rate": 0.000208765,
      "loss": 0.0,
      "step": 58300
    },
    {
      "epoch": 5.837081459270365,
      "grad_norm": 5.681956571912394e-10,
      "learning_rate": 0.000208265,
      "loss": 0.0,
      "step": 58400
    },
    {
      "epoch": 5.847076461769116,
      "grad_norm": 5.626888399667962e-10,
      "learning_rate": 0.000207765,
      "loss": 0.0,
      "step": 58500
    },
    {
      "epoch": 5.857071464267866,
      "grad_norm": 5.738329811322274e-10,
      "learning_rate": 0.00020726500000000002,
      "loss": 0.0,
      "step": 58600
    },
    {
      "epoch": 5.867066466766617,
      "grad_norm": 5.669036351463319e-10,
      "learning_rate": 0.000206765,
      "loss": 0.0,
      "step": 58700
    },
    {
      "epoch": 5.877061469265367,
      "grad_norm": 5.637097455490903e-10,
      "learning_rate": 0.00020626500000000002,
      "loss": 0.0,
      "step": 58800
    },
    {
      "epoch": 5.887056471764118,
      "grad_norm": 5.872693442654509e-10,
      "learning_rate": 0.000205765,
      "loss": 0.0,
      "step": 58900
    },
    {
      "epoch": 5.897051474262868,
      "grad_norm": 5.733842289856739e-10,
      "learning_rate": 0.000205265,
      "loss": 0.0,
      "step": 59000
    },
    {
      "epoch": 5.907046476761619,
      "grad_norm": 5.831127802835567e-10,
      "learning_rate": 0.000204765,
      "loss": 0.0,
      "step": 59100
    },
    {
      "epoch": 5.917041479260369,
      "grad_norm": 5.489300125560703e-10,
      "learning_rate": 0.000204265,
      "loss": 0.0,
      "step": 59200
    },
    {
      "epoch": 5.927036481759121,
      "grad_norm": 5.592558083300503e-10,
      "learning_rate": 0.000203765,
      "loss": 0.0,
      "step": 59300
    },
    {
      "epoch": 5.937031484257871,
      "grad_norm": 5.587858509237265e-10,
      "learning_rate": 0.000203265,
      "loss": 0.0,
      "step": 59400
    },
    {
      "epoch": 5.947026486756622,
      "grad_norm": 5.675125924753388e-10,
      "learning_rate": 0.00020276500000000001,
      "loss": 0.0,
      "step": 59500
    },
    {
      "epoch": 5.957021489255372,
      "grad_norm": 5.582995177277894e-10,
      "learning_rate": 0.000202265,
      "loss": 0.0,
      "step": 59600
    },
    {
      "epoch": 5.967016491754123,
      "grad_norm": 5.65178737144123e-10,
      "learning_rate": 0.00020176500000000002,
      "loss": 0.0,
      "step": 59700
    },
    {
      "epoch": 5.977011494252873,
      "grad_norm": 5.642507572289901e-10,
      "learning_rate": 0.000201265,
      "loss": 0.0,
      "step": 59800
    },
    {
      "epoch": 5.987006496751624,
      "grad_norm": 5.686329740406393e-10,
      "learning_rate": 0.000200765,
      "loss": 0.0,
      "step": 59900
    },
    {
      "epoch": 5.997001499250375,
      "grad_norm": 5.700451777279625e-10,
      "learning_rate": 0.000200265,
      "loss": 0.0,
      "step": 60000
    },
    {
      "epoch": 6.006996501749126,
      "grad_norm": 5.645612310978265e-10,
      "learning_rate": 0.000199765,
      "loss": 0.0,
      "step": 60100
    },
    {
      "epoch": 6.016991504247876,
      "grad_norm": 5.892798471407446e-10,
      "learning_rate": 0.000199265,
      "loss": 0.0,
      "step": 60200
    },
    {
      "epoch": 6.026986506746627,
      "grad_norm": 5.711834893951107e-10,
      "learning_rate": 0.000198765,
      "loss": 0.0,
      "step": 60300
    },
    {
      "epoch": 6.036981509245377,
      "grad_norm": 5.72791591935129e-10,
      "learning_rate": 0.000198265,
      "loss": 0.0,
      "step": 60400
    },
    {
      "epoch": 6.046976511744128,
      "grad_norm": 5.505640388037136e-10,
      "learning_rate": 0.000197765,
      "loss": 0.0,
      "step": 60500
    },
    {
      "epoch": 6.056971514242878,
      "grad_norm": 5.820801618483529e-10,
      "learning_rate": 0.000197265,
      "loss": 0.0,
      "step": 60600
    },
    {
      "epoch": 6.066966516741629,
      "grad_norm": 5.630967359060435e-10,
      "learning_rate": 0.000196765,
      "loss": 0.0,
      "step": 60700
    },
    {
      "epoch": 6.076961519240379,
      "grad_norm": 5.654041124181219e-10,
      "learning_rate": 0.000196265,
      "loss": 0.0,
      "step": 60800
    },
    {
      "epoch": 6.086956521739131,
      "grad_norm": 5.64984781181721e-10,
      "learning_rate": 0.000195765,
      "loss": 0.0,
      "step": 60900
    },
    {
      "epoch": 6.096951524237881,
      "grad_norm": 5.6452126306894e-10,
      "learning_rate": 0.000195265,
      "loss": 0.0,
      "step": 61000
    },
    {
      "epoch": 6.106946526736632,
      "grad_norm": 5.81626746765096e-10,
      "learning_rate": 0.000194765,
      "loss": 0.0,
      "step": 61100
    },
    {
      "epoch": 6.116941529235382,
      "grad_norm": 5.579833817215274e-10,
      "learning_rate": 0.000194265,
      "loss": 0.0,
      "step": 61200
    },
    {
      "epoch": 6.126936531734133,
      "grad_norm": 5.436456285146107e-10,
      "learning_rate": 0.00019376499999999999,
      "loss": 0.0,
      "step": 61300
    },
    {
      "epoch": 6.136931534232883,
      "grad_norm": 5.625028776101715e-10,
      "learning_rate": 0.000193265,
      "loss": 0.0,
      "step": 61400
    },
    {
      "epoch": 6.146926536731634,
      "grad_norm": 5.615972686889847e-10,
      "learning_rate": 0.000192765,
      "loss": 0.0,
      "step": 61500
    },
    {
      "epoch": 6.156921539230384,
      "grad_norm": 5.630416688440221e-10,
      "learning_rate": 0.000192265,
      "loss": 0.0,
      "step": 61600
    },
    {
      "epoch": 6.166916541729136,
      "grad_norm": 5.707539996180344e-10,
      "learning_rate": 0.000191765,
      "loss": 0.0,
      "step": 61700
    },
    {
      "epoch": 6.176911544227886,
      "grad_norm": 5.69376545911382e-10,
      "learning_rate": 0.000191265,
      "loss": 0.0,
      "step": 61800
    },
    {
      "epoch": 6.186906546726637,
      "grad_norm": 5.577738826367806e-10,
      "learning_rate": 0.000190765,
      "loss": 0.0,
      "step": 61900
    },
    {
      "epoch": 6.196901549225387,
      "grad_norm": 5.565786720396204e-10,
      "learning_rate": 0.00019026499999999998,
      "loss": 0.0,
      "step": 62000
    },
    {
      "epoch": 6.206896551724138,
      "grad_norm": 5.689981263934385e-10,
      "learning_rate": 0.000189765,
      "loss": 0.0,
      "step": 62100
    },
    {
      "epoch": 6.216891554222888,
      "grad_norm": 5.683167270120748e-10,
      "learning_rate": 0.00018926499999999998,
      "loss": 0.0,
      "step": 62200
    },
    {
      "epoch": 6.226886556721639,
      "grad_norm": 5.498638211420825e-10,
      "learning_rate": 0.000188765,
      "loss": 0.0,
      "step": 62300
    },
    {
      "epoch": 6.2368815592203894,
      "grad_norm": 5.703936212242411e-10,
      "learning_rate": 0.000188265,
      "loss": 0.0,
      "step": 62400
    },
    {
      "epoch": 6.246876561719141,
      "grad_norm": 5.689405613296117e-10,
      "learning_rate": 0.000187765,
      "loss": 0.0,
      "step": 62500
    },
    {
      "epoch": 6.256871564217891,
      "grad_norm": 5.621755283513608e-10,
      "learning_rate": 0.000187265,
      "loss": 0.0,
      "step": 62600
    },
    {
      "epoch": 6.266866566716642,
      "grad_norm": 5.687807447252169e-10,
      "learning_rate": 0.00018676499999999998,
      "loss": 0.0,
      "step": 62700
    },
    {
      "epoch": 6.276861569215392,
      "grad_norm": 5.488567933475963e-10,
      "learning_rate": 0.000186265,
      "loss": 0.0,
      "step": 62800
    },
    {
      "epoch": 6.286856571714143,
      "grad_norm": 5.653335022337558e-10,
      "learning_rate": 0.000185765,
      "loss": 0.0,
      "step": 62900
    },
    {
      "epoch": 6.296851574212893,
      "grad_norm": 5.608742914553488e-10,
      "learning_rate": 0.00018526500000000002,
      "loss": 0.0,
      "step": 63000
    },
    {
      "epoch": 6.306846576711644,
      "grad_norm": 5.643707168268008e-10,
      "learning_rate": 0.000184765,
      "loss": 0.0,
      "step": 63100
    },
    {
      "epoch": 6.3168415792103945,
      "grad_norm": 5.528184576775175e-10,
      "learning_rate": 0.00018426500000000003,
      "loss": 0.0,
      "step": 63200
    },
    {
      "epoch": 6.326836581709145,
      "grad_norm": 5.708284955829868e-10,
      "learning_rate": 0.000183765,
      "loss": 0.0,
      "step": 63300
    },
    {
      "epoch": 6.336831584207896,
      "grad_norm": 5.763519661527994e-10,
      "learning_rate": 0.00018326500000000003,
      "loss": 0.0,
      "step": 63400
    },
    {
      "epoch": 6.346826586706647,
      "grad_norm": 5.486409659916092e-10,
      "learning_rate": 0.00018276500000000002,
      "loss": 0.0,
      "step": 63500
    },
    {
      "epoch": 6.356821589205397,
      "grad_norm": 5.543042136402221e-10,
      "learning_rate": 0.000182265,
      "loss": 0.0,
      "step": 63600
    },
    {
      "epoch": 6.366816591704148,
      "grad_norm": 5.611783815417937e-10,
      "learning_rate": 0.00018176500000000002,
      "loss": 0.0,
      "step": 63700
    },
    {
      "epoch": 6.3768115942028984,
      "grad_norm": 5.699163363459547e-10,
      "learning_rate": 0.000181265,
      "loss": 0.0,
      "step": 63800
    },
    {
      "epoch": 6.386806596701649,
      "grad_norm": 5.601388242126859e-10,
      "learning_rate": 0.00018076500000000002,
      "loss": 0.0,
      "step": 63900
    },
    {
      "epoch": 6.3968015992003995,
      "grad_norm": 5.650315215710577e-10,
      "learning_rate": 0.000180265,
      "loss": 0.0,
      "step": 64000
    },
    {
      "epoch": 6.406796601699151,
      "grad_norm": 5.545390258099303e-10,
      "learning_rate": 0.00017976500000000002,
      "loss": 0.0,
      "step": 64100
    },
    {
      "epoch": 6.416791604197901,
      "grad_norm": 5.544988912475901e-10,
      "learning_rate": 0.000179265,
      "loss": 0.0,
      "step": 64200
    },
    {
      "epoch": 6.426786606696652,
      "grad_norm": 5.465747854316305e-10,
      "learning_rate": 0.000178765,
      "loss": 0.0,
      "step": 64300
    },
    {
      "epoch": 6.436781609195402,
      "grad_norm": 5.719130169445918e-10,
      "learning_rate": 0.00017826500000000002,
      "loss": 0.0,
      "step": 64400
    },
    {
      "epoch": 6.446776611694153,
      "grad_norm": 5.625195309555409e-10,
      "learning_rate": 0.000177765,
      "loss": 0.0,
      "step": 64500
    },
    {
      "epoch": 6.4567716141929035,
      "grad_norm": 5.624889443112124e-10,
      "learning_rate": 0.00017726500000000002,
      "loss": 0.0,
      "step": 64600
    },
    {
      "epoch": 6.466766616691654,
      "grad_norm": 5.609218090008028e-10,
      "learning_rate": 0.000176765,
      "loss": 0.0,
      "step": 64700
    },
    {
      "epoch": 6.4767616191904045,
      "grad_norm": 5.556639592896317e-10,
      "learning_rate": 0.00017626500000000002,
      "loss": 0.0,
      "step": 64800
    },
    {
      "epoch": 6.486756621689155,
      "grad_norm": 5.522185486661613e-10,
      "learning_rate": 0.000175765,
      "loss": 0.0,
      "step": 64900
    },
    {
      "epoch": 6.496751624187906,
      "grad_norm": 5.609541164908194e-10,
      "learning_rate": 0.000175265,
      "loss": 0.0,
      "step": 65000
    },
    {
      "epoch": 6.506746626686657,
      "grad_norm": 5.583219997440381e-10,
      "learning_rate": 0.000174765,
      "loss": 0.0,
      "step": 65100
    },
    {
      "epoch": 6.5167416291854074,
      "grad_norm": 5.647388112706153e-10,
      "learning_rate": 0.000174265,
      "loss": 0.0,
      "step": 65200
    },
    {
      "epoch": 6.526736631684158,
      "grad_norm": 5.586864859630225e-10,
      "learning_rate": 0.00017376500000000001,
      "loss": 0.0,
      "step": 65300
    },
    {
      "epoch": 6.5367316341829085,
      "grad_norm": 5.609882003376754e-10,
      "learning_rate": 0.000173265,
      "loss": 0.0,
      "step": 65400
    },
    {
      "epoch": 6.546726636681659,
      "grad_norm": 5.558381532821954e-10,
      "learning_rate": 0.00017276500000000002,
      "loss": 0.0,
      "step": 65500
    },
    {
      "epoch": 6.5567216391804095,
      "grad_norm": 5.55964552173549e-10,
      "learning_rate": 0.000172265,
      "loss": 0.0,
      "step": 65600
    },
    {
      "epoch": 6.566716641679161,
      "grad_norm": 5.757404553108358e-10,
      "learning_rate": 0.000171765,
      "loss": 0.0,
      "step": 65700
    },
    {
      "epoch": 6.576711644177911,
      "grad_norm": 5.526509805342528e-10,
      "learning_rate": 0.000171265,
      "loss": 0.0,
      "step": 65800
    },
    {
      "epoch": 6.586706646676662,
      "grad_norm": 5.544738557183848e-10,
      "learning_rate": 0.000170765,
      "loss": 0.0,
      "step": 65900
    },
    {
      "epoch": 6.5967016491754125,
      "grad_norm": 5.541655467844464e-10,
      "learning_rate": 0.000170265,
      "loss": 0.0,
      "step": 66000
    },
    {
      "epoch": 6.606696651674163,
      "grad_norm": 5.542267755842545e-10,
      "learning_rate": 0.000169765,
      "loss": 0.0,
      "step": 66100
    },
    {
      "epoch": 6.6166916541729135,
      "grad_norm": 5.569413819017655e-10,
      "learning_rate": 0.000169265,
      "loss": 0.0,
      "step": 66200
    },
    {
      "epoch": 6.626686656671664,
      "grad_norm": 5.556533566597466e-10,
      "learning_rate": 0.000168765,
      "loss": 0.0,
      "step": 66300
    },
    {
      "epoch": 6.6366816591704145,
      "grad_norm": 5.438727246342978e-10,
      "learning_rate": 0.000168265,
      "loss": 0.0,
      "step": 66400
    },
    {
      "epoch": 6.646676661669165,
      "grad_norm": 5.521648138717694e-10,
      "learning_rate": 0.000167765,
      "loss": 0.0,
      "step": 66500
    },
    {
      "epoch": 6.6566716641679164,
      "grad_norm": 5.506635702978713e-10,
      "learning_rate": 0.000167265,
      "loss": 0.0,
      "step": 66600
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 5.642240563652479e-10,
      "learning_rate": 0.000166765,
      "loss": 0.0,
      "step": 66700
    },
    {
      "epoch": 6.6766616691654175,
      "grad_norm": 5.462789109955679e-10,
      "learning_rate": 0.000166265,
      "loss": 0.0,
      "step": 66800
    },
    {
      "epoch": 6.686656671664168,
      "grad_norm": 5.635455990748994e-10,
      "learning_rate": 0.000165765,
      "loss": 0.0,
      "step": 66900
    },
    {
      "epoch": 6.6966516741629185,
      "grad_norm": 5.545709447218883e-10,
      "learning_rate": 0.000165265,
      "loss": 0.0,
      "step": 67000
    },
    {
      "epoch": 6.706646676661669,
      "grad_norm": 5.552079906934182e-10,
      "learning_rate": 0.00016476499999999999,
      "loss": 0.0,
      "step": 67100
    },
    {
      "epoch": 6.7166416791604195,
      "grad_norm": 5.520385260027183e-10,
      "learning_rate": 0.000164265,
      "loss": 0.0,
      "step": 67200
    },
    {
      "epoch": 6.72663668165917,
      "grad_norm": 5.490058962998035e-10,
      "learning_rate": 0.000163765,
      "loss": 0.0,
      "step": 67300
    },
    {
      "epoch": 6.736631684157921,
      "grad_norm": 5.566569982740077e-10,
      "learning_rate": 0.000163265,
      "loss": 0.0,
      "step": 67400
    },
    {
      "epoch": 6.746626686656672,
      "grad_norm": 5.514999568134726e-10,
      "learning_rate": 0.000162765,
      "loss": 0.0,
      "step": 67500
    },
    {
      "epoch": 6.7566216891554225,
      "grad_norm": 5.44912615030313e-10,
      "learning_rate": 0.000162265,
      "loss": 0.0,
      "step": 67600
    },
    {
      "epoch": 6.766616691654173,
      "grad_norm": 5.537664771182449e-10,
      "learning_rate": 0.000161765,
      "loss": 0.0,
      "step": 67700
    },
    {
      "epoch": 6.7766116941529235,
      "grad_norm": 5.484367959773806e-10,
      "learning_rate": 0.00016126499999999998,
      "loss": 0.0,
      "step": 67800
    },
    {
      "epoch": 6.786606696651674,
      "grad_norm": 5.548265735733082e-10,
      "learning_rate": 0.000160765,
      "loss": 0.0,
      "step": 67900
    },
    {
      "epoch": 6.796601699150425,
      "grad_norm": 5.542301617644796e-10,
      "learning_rate": 0.00016026499999999998,
      "loss": 0.0,
      "step": 68000
    },
    {
      "epoch": 6.806596701649175,
      "grad_norm": 5.343046005634733e-10,
      "learning_rate": 0.000159765,
      "loss": 0.0,
      "step": 68100
    },
    {
      "epoch": 6.8165917041479265,
      "grad_norm": 5.420944804157557e-10,
      "learning_rate": 0.000159265,
      "loss": 0.0,
      "step": 68200
    },
    {
      "epoch": 6.826586706646677,
      "grad_norm": 5.498443922391516e-10,
      "learning_rate": 0.000158765,
      "loss": 0.0,
      "step": 68300
    },
    {
      "epoch": 6.8365817091454275,
      "grad_norm": 5.520459089858321e-10,
      "learning_rate": 0.000158265,
      "loss": 0.0,
      "step": 68400
    },
    {
      "epoch": 6.846576711644178,
      "grad_norm": 5.451564200065206e-10,
      "learning_rate": 0.000157765,
      "loss": 0.0,
      "step": 68500
    },
    {
      "epoch": 6.8565717141429285,
      "grad_norm": 5.394360513832908e-10,
      "learning_rate": 0.000157265,
      "loss": 0.0,
      "step": 68600
    },
    {
      "epoch": 6.866566716641679,
      "grad_norm": 5.556322069111275e-10,
      "learning_rate": 0.00015676499999999998,
      "loss": 0.0,
      "step": 68700
    },
    {
      "epoch": 6.87656171914043,
      "grad_norm": 5.463791641346916e-10,
      "learning_rate": 0.000156265,
      "loss": 0.0,
      "step": 68800
    },
    {
      "epoch": 6.88655672163918,
      "grad_norm": 5.572100558737247e-10,
      "learning_rate": 0.00015576499999999998,
      "loss": 0.0,
      "step": 68900
    },
    {
      "epoch": 6.896551724137931,
      "grad_norm": 5.694472671180506e-10,
      "learning_rate": 0.000155265,
      "loss": 0.0,
      "step": 69000
    },
    {
      "epoch": 6.906546726636682,
      "grad_norm": 5.485188414589004e-10,
      "learning_rate": 0.000154765,
      "loss": 0.0,
      "step": 69100
    },
    {
      "epoch": 6.9165417291354325,
      "grad_norm": 5.616039300271325e-10,
      "learning_rate": 0.00015426500000000003,
      "loss": 0.0,
      "step": 69200
    },
    {
      "epoch": 6.926536731634183,
      "grad_norm": 5.365187738526345e-10,
      "learning_rate": 0.00015376500000000002,
      "loss": 0.0,
      "step": 69300
    },
    {
      "epoch": 6.936531734132934,
      "grad_norm": 5.536485159218785e-10,
      "learning_rate": 0.000153265,
      "loss": 0.0,
      "step": 69400
    },
    {
      "epoch": 6.946526736631684,
      "grad_norm": 5.478191789087816e-10,
      "learning_rate": 0.00015276500000000002,
      "loss": 0.0,
      "step": 69500
    },
    {
      "epoch": 6.956521739130435,
      "grad_norm": 5.638328692825212e-10,
      "learning_rate": 0.000152265,
      "loss": 0.0,
      "step": 69600
    },
    {
      "epoch": 6.966516741629185,
      "grad_norm": 5.563645655293215e-10,
      "learning_rate": 0.00015176500000000002,
      "loss": 0.0,
      "step": 69700
    },
    {
      "epoch": 6.9765117441279365,
      "grad_norm": 5.433384853148482e-10,
      "learning_rate": 0.000151265,
      "loss": 0.0,
      "step": 69800
    },
    {
      "epoch": 6.986506746626687,
      "grad_norm": 5.50890333350651e-10,
      "learning_rate": 0.00015076500000000002,
      "loss": 0.0,
      "step": 69900
    },
    {
      "epoch": 6.9965017491254375,
      "grad_norm": 5.384570567201763e-10,
      "learning_rate": 0.000150265,
      "loss": 0.0,
      "step": 70000
    },
    {
      "epoch": 7.006496751624188,
      "grad_norm": 5.387921220290082e-10,
      "learning_rate": 0.000149765,
      "loss": 0.0,
      "step": 70100
    },
    {
      "epoch": 7.016491754122939,
      "grad_norm": 5.508351552663271e-10,
      "learning_rate": 0.00014926500000000002,
      "loss": 0.0,
      "step": 70200
    },
    {
      "epoch": 7.026486756621689,
      "grad_norm": 5.435959460342588e-10,
      "learning_rate": 0.000148765,
      "loss": 0.0,
      "step": 70300
    },
    {
      "epoch": 7.03648175912044,
      "grad_norm": 5.550148118871334e-10,
      "learning_rate": 0.00014826500000000002,
      "loss": 0.0,
      "step": 70400
    },
    {
      "epoch": 7.04647676161919,
      "grad_norm": 5.539754766026306e-10,
      "learning_rate": 0.000147765,
      "loss": 0.0,
      "step": 70500
    },
    {
      "epoch": 7.056471764117941,
      "grad_norm": 5.469914521327723e-10,
      "learning_rate": 0.00014726500000000002,
      "loss": 0.0,
      "step": 70600
    },
    {
      "epoch": 7.066466766616692,
      "grad_norm": 5.451266105183095e-10,
      "learning_rate": 0.000146765,
      "loss": 0.0,
      "step": 70700
    },
    {
      "epoch": 7.076461769115443,
      "grad_norm": 5.419762416636331e-10,
      "learning_rate": 0.000146265,
      "loss": 0.0,
      "step": 70800
    },
    {
      "epoch": 7.086456771614193,
      "grad_norm": 5.463394736615612e-10,
      "learning_rate": 0.000145765,
      "loss": 0.0,
      "step": 70900
    },
    {
      "epoch": 7.096451774112944,
      "grad_norm": 5.450054851863229e-10,
      "learning_rate": 0.000145265,
      "loss": 0.0,
      "step": 71000
    },
    {
      "epoch": 7.106446776611694,
      "grad_norm": 5.652898149577368e-10,
      "learning_rate": 0.00014476500000000001,
      "loss": 0.0,
      "step": 71100
    },
    {
      "epoch": 7.116441779110445,
      "grad_norm": 5.462111873910658e-10,
      "learning_rate": 0.000144265,
      "loss": 0.0,
      "step": 71200
    },
    {
      "epoch": 7.126436781609195,
      "grad_norm": 5.414511616841367e-10,
      "learning_rate": 0.00014376500000000002,
      "loss": 0.0,
      "step": 71300
    },
    {
      "epoch": 7.136431784107946,
      "grad_norm": 5.412817416505789e-10,
      "learning_rate": 0.000143265,
      "loss": 0.0,
      "step": 71400
    },
    {
      "epoch": 7.146426786606697,
      "grad_norm": 5.485035203811606e-10,
      "learning_rate": 0.000142765,
      "loss": 0.0,
      "step": 71500
    },
    {
      "epoch": 7.156421789105448,
      "grad_norm": 6.696720400434231e-10,
      "learning_rate": 0.000142265,
      "loss": 0.0,
      "step": 71600
    },
    {
      "epoch": 7.166416791604198,
      "grad_norm": 5.399468094857696e-10,
      "learning_rate": 0.000141765,
      "loss": 0.0,
      "step": 71700
    },
    {
      "epoch": 7.176411794102949,
      "grad_norm": 5.572172168122336e-10,
      "learning_rate": 0.000141265,
      "loss": 0.0,
      "step": 71800
    },
    {
      "epoch": 7.186406796601699,
      "grad_norm": 5.443875905619677e-10,
      "learning_rate": 0.000140765,
      "loss": 0.0,
      "step": 71900
    },
    {
      "epoch": 7.19640179910045,
      "grad_norm": 5.404248715201732e-10,
      "learning_rate": 0.000140265,
      "loss": 0.0,
      "step": 72000
    },
    {
      "epoch": 7.2063968015992,
      "grad_norm": 5.611666686888839e-10,
      "learning_rate": 0.000139765,
      "loss": 0.0,
      "step": 72100
    },
    {
      "epoch": 7.216391804097951,
      "grad_norm": 5.413912096408069e-10,
      "learning_rate": 0.00013926500000000002,
      "loss": 0.0,
      "step": 72200
    },
    {
      "epoch": 7.226386806596702,
      "grad_norm": 5.561562321787505e-10,
      "learning_rate": 0.000138765,
      "loss": 0.0,
      "step": 72300
    },
    {
      "epoch": 7.236381809095453,
      "grad_norm": 5.478252851354171e-10,
      "learning_rate": 0.000138265,
      "loss": 0.0,
      "step": 72400
    },
    {
      "epoch": 7.246376811594203,
      "grad_norm": 5.504721123372747e-10,
      "learning_rate": 0.000137765,
      "loss": 0.0,
      "step": 72500
    },
    {
      "epoch": 7.256371814092954,
      "grad_norm": 5.457383989160292e-10,
      "learning_rate": 0.000137265,
      "loss": 0.0,
      "step": 72600
    },
    {
      "epoch": 7.266366816591704,
      "grad_norm": 5.359492294410018e-10,
      "learning_rate": 0.000136765,
      "loss": 0.0,
      "step": 72700
    },
    {
      "epoch": 7.276361819090455,
      "grad_norm": 5.400007108136151e-10,
      "learning_rate": 0.000136265,
      "loss": 0.0,
      "step": 72800
    },
    {
      "epoch": 7.286356821589205,
      "grad_norm": 5.421489368551136e-10,
      "learning_rate": 0.000135765,
      "loss": 0.0,
      "step": 72900
    },
    {
      "epoch": 7.296351824087956,
      "grad_norm": 5.476405440241194e-10,
      "learning_rate": 0.000135265,
      "loss": 0.0,
      "step": 73000
    },
    {
      "epoch": 7.306346826586706,
      "grad_norm": 5.418833715076232e-10,
      "learning_rate": 0.000134765,
      "loss": 0.0,
      "step": 73100
    },
    {
      "epoch": 7.316341829085458,
      "grad_norm": 5.362258415075871e-10,
      "learning_rate": 0.000134265,
      "loss": 0.0,
      "step": 73200
    },
    {
      "epoch": 7.326336831584208,
      "grad_norm": 5.442130079913454e-10,
      "learning_rate": 0.000133765,
      "loss": 0.0,
      "step": 73300
    },
    {
      "epoch": 7.336331834082959,
      "grad_norm": 5.423277382732294e-10,
      "learning_rate": 0.000133265,
      "loss": 0.0,
      "step": 73400
    },
    {
      "epoch": 7.346326836581709,
      "grad_norm": 5.540555791938573e-10,
      "learning_rate": 0.000132765,
      "loss": 0.0,
      "step": 73500
    },
    {
      "epoch": 7.35632183908046,
      "grad_norm": 5.428445470911925e-10,
      "learning_rate": 0.000132265,
      "loss": 0.0,
      "step": 73600
    },
    {
      "epoch": 7.36631684157921,
      "grad_norm": 5.419452109300948e-10,
      "learning_rate": 0.00013177,
      "loss": 0.0,
      "step": 73700
    },
    {
      "epoch": 7.376311844077961,
      "grad_norm": 5.484120935150827e-10,
      "learning_rate": 0.00013127,
      "loss": 0.0,
      "step": 73800
    },
    {
      "epoch": 7.386306846576712,
      "grad_norm": 5.458656304746512e-10,
      "learning_rate": 0.00013077,
      "loss": 0.0,
      "step": 73900
    },
    {
      "epoch": 7.396301849075463,
      "grad_norm": 5.309003792142164e-10,
      "learning_rate": 0.00013027,
      "loss": 0.0,
      "step": 74000
    },
    {
      "epoch": 7.406296851574213,
      "grad_norm": 5.512008627306386e-10,
      "learning_rate": 0.00012977,
      "loss": 0.0,
      "step": 74100
    },
    {
      "epoch": 7.416291854072964,
      "grad_norm": 5.362087995841591e-10,
      "learning_rate": 0.00012927,
      "loss": 0.0,
      "step": 74200
    },
    {
      "epoch": 7.426286856571714,
      "grad_norm": 5.453956175571761e-10,
      "learning_rate": 0.00012877,
      "loss": 0.0,
      "step": 74300
    },
    {
      "epoch": 7.436281859070465,
      "grad_norm": 5.548828618806567e-10,
      "learning_rate": 0.00012827,
      "loss": 0.0,
      "step": 74400
    },
    {
      "epoch": 7.446276861569215,
      "grad_norm": 5.317546958316655e-10,
      "learning_rate": 0.00012777,
      "loss": 0.0,
      "step": 74500
    },
    {
      "epoch": 7.456271864067966,
      "grad_norm": 5.429007798873897e-10,
      "learning_rate": 0.00012727,
      "loss": 0.0,
      "step": 74600
    },
    {
      "epoch": 7.466266866566716,
      "grad_norm": 5.437171823885478e-10,
      "learning_rate": 0.00012677,
      "loss": 0.0,
      "step": 74700
    },
    {
      "epoch": 7.476261869065468,
      "grad_norm": 5.525858104427073e-10,
      "learning_rate": 0.00012627,
      "loss": 0.0,
      "step": 74800
    },
    {
      "epoch": 7.486256871564218,
      "grad_norm": 5.482121978594989e-10,
      "learning_rate": 0.00012576999999999998,
      "loss": 0.0,
      "step": 74900
    },
    {
      "epoch": 7.496251874062969,
      "grad_norm": 5.49867040788854e-10,
      "learning_rate": 0.00012527,
      "loss": 0.0,
      "step": 75000
    },
    {
      "epoch": 7.506246876561719,
      "grad_norm": 5.478246745127535e-10,
      "learning_rate": 0.00012477,
      "loss": 0.0,
      "step": 75100
    },
    {
      "epoch": 7.51624187906047,
      "grad_norm": 5.488621779292657e-10,
      "learning_rate": 0.00012427,
      "loss": 0.0,
      "step": 75200
    },
    {
      "epoch": 7.52623688155922,
      "grad_norm": 5.44759959364427e-10,
      "learning_rate": 0.00012377000000000002,
      "loss": 0.0,
      "step": 75300
    },
    {
      "epoch": 7.536231884057971,
      "grad_norm": 5.621924592524863e-10,
      "learning_rate": 0.00012327,
      "loss": 0.0,
      "step": 75400
    },
    {
      "epoch": 7.546226886556722,
      "grad_norm": 5.596149099673653e-10,
      "learning_rate": 0.00012277000000000002,
      "loss": 0.0,
      "step": 75500
    },
    {
      "epoch": 7.556221889055473,
      "grad_norm": 5.428662519513239e-10,
      "learning_rate": 0.00012227,
      "loss": 0.0,
      "step": 75600
    },
    {
      "epoch": 7.566216891554223,
      "grad_norm": 5.49170209307448e-10,
      "learning_rate": 0.00012177000000000001,
      "loss": 0.0,
      "step": 75700
    },
    {
      "epoch": 7.576211894052974,
      "grad_norm": 5.432212457634478e-10,
      "learning_rate": 0.00012127000000000001,
      "loss": 0.0,
      "step": 75800
    },
    {
      "epoch": 7.586206896551724,
      "grad_norm": 5.512618694858418e-10,
      "learning_rate": 0.00012077000000000001,
      "loss": 0.0,
      "step": 75900
    },
    {
      "epoch": 7.596201899050475,
      "grad_norm": 5.35630040321422e-10,
      "learning_rate": 0.00012027,
      "loss": 0.0,
      "step": 76000
    },
    {
      "epoch": 7.606196901549225,
      "grad_norm": 5.434892536015923e-10,
      "learning_rate": 0.00011977,
      "loss": 0.0,
      "step": 76100
    },
    {
      "epoch": 7.616191904047976,
      "grad_norm": 5.590278240319435e-10,
      "learning_rate": 0.00011927,
      "loss": 0.0,
      "step": 76200
    },
    {
      "epoch": 7.626186906546726,
      "grad_norm": 5.546118009291945e-10,
      "learning_rate": 0.00011877,
      "loss": 0.0,
      "step": 76300
    },
    {
      "epoch": 7.636181909045478,
      "grad_norm": 5.505455535903536e-10,
      "learning_rate": 0.00011827,
      "loss": 0.0,
      "step": 76400
    },
    {
      "epoch": 7.646176911544228,
      "grad_norm": 5.410538683747745e-10,
      "learning_rate": 0.00011777,
      "loss": 0.0,
      "step": 76500
    },
    {
      "epoch": 7.656171914042979,
      "grad_norm": 5.470840447330261e-10,
      "learning_rate": 0.00011727000000000001,
      "loss": 0.0,
      "step": 76600
    },
    {
      "epoch": 7.666166916541729,
      "grad_norm": 5.336836528258004e-10,
      "learning_rate": 0.00011677,
      "loss": 0.0,
      "step": 76700
    },
    {
      "epoch": 7.67616191904048,
      "grad_norm": 5.374874434416199e-10,
      "learning_rate": 0.00011627,
      "loss": 0.0,
      "step": 76800
    },
    {
      "epoch": 7.68615692153923,
      "grad_norm": 5.347979836756167e-10,
      "learning_rate": 0.00011577500000000001,
      "loss": 0.0,
      "step": 76900
    },
    {
      "epoch": 7.696151924037981,
      "grad_norm": 5.438029471172001e-10,
      "learning_rate": 0.00011527500000000001,
      "loss": 0.0,
      "step": 77000
    },
    {
      "epoch": 7.706146926536731,
      "grad_norm": 5.423019255879069e-10,
      "learning_rate": 0.000114775,
      "loss": 0.0,
      "step": 77100
    },
    {
      "epoch": 7.716141929035482,
      "grad_norm": 5.367950528523124e-10,
      "learning_rate": 0.000114275,
      "loss": 0.0,
      "step": 77200
    },
    {
      "epoch": 7.726136931534233,
      "grad_norm": 5.393254731700381e-10,
      "learning_rate": 0.000113775,
      "loss": 0.0,
      "step": 77300
    },
    {
      "epoch": 7.736131934032984,
      "grad_norm": 5.400065949956456e-10,
      "learning_rate": 0.000113275,
      "loss": 0.0,
      "step": 77400
    },
    {
      "epoch": 7.746126936531734,
      "grad_norm": 5.482789777744301e-10,
      "learning_rate": 0.000112775,
      "loss": 0.0,
      "step": 77500
    },
    {
      "epoch": 7.756121939030485,
      "grad_norm": 5.383768431066471e-10,
      "learning_rate": 0.000112275,
      "loss": 0.0,
      "step": 77600
    },
    {
      "epoch": 7.766116941529235,
      "grad_norm": 5.355305088272644e-10,
      "learning_rate": 0.000111775,
      "loss": 0.0,
      "step": 77700
    },
    {
      "epoch": 7.776111944027986,
      "grad_norm": 5.346544873496839e-10,
      "learning_rate": 0.00011127500000000001,
      "loss": 0.0,
      "step": 77800
    },
    {
      "epoch": 7.786106946526736,
      "grad_norm": 5.327300267587987e-10,
      "learning_rate": 0.000110775,
      "loss": 0.0,
      "step": 77900
    },
    {
      "epoch": 7.796101949025488,
      "grad_norm": 5.395041635658515e-10,
      "learning_rate": 0.000110275,
      "loss": 0.0,
      "step": 78000
    },
    {
      "epoch": 7.806096951524238,
      "grad_norm": 5.416128101565221e-10,
      "learning_rate": 0.000109775,
      "loss": 0.0,
      "step": 78100
    },
    {
      "epoch": 7.816091954022989,
      "grad_norm": 5.574124495311139e-10,
      "learning_rate": 0.000109275,
      "loss": 0.0,
      "step": 78200
    },
    {
      "epoch": 7.826086956521739,
      "grad_norm": 5.413141046517467e-10,
      "learning_rate": 0.000108775,
      "loss": 0.0,
      "step": 78300
    },
    {
      "epoch": 7.83608195902049,
      "grad_norm": 5.488308141288201e-10,
      "learning_rate": 0.000108275,
      "loss": 0.0,
      "step": 78400
    },
    {
      "epoch": 7.84607696151924,
      "grad_norm": 5.43067424363386e-10,
      "learning_rate": 0.000107775,
      "loss": 0.0,
      "step": 78500
    },
    {
      "epoch": 7.856071964017991,
      "grad_norm": 5.475083164618866e-10,
      "learning_rate": 0.00010727499999999999,
      "loss": 0.0,
      "step": 78600
    },
    {
      "epoch": 7.866066966516741,
      "grad_norm": 5.347276510470067e-10,
      "learning_rate": 0.000106775,
      "loss": 0.0,
      "step": 78700
    },
    {
      "epoch": 7.876061969015492,
      "grad_norm": 5.374753975218027e-10,
      "learning_rate": 0.000106275,
      "loss": 0.0,
      "step": 78800
    },
    {
      "epoch": 7.886056971514243,
      "grad_norm": 5.336582842296878e-10,
      "learning_rate": 0.000105775,
      "loss": 0.0,
      "step": 78900
    },
    {
      "epoch": 7.896051974012994,
      "grad_norm": 5.335371588977011e-10,
      "learning_rate": 0.000105275,
      "loss": 0.0,
      "step": 79000
    },
    {
      "epoch": 7.906046976511744,
      "grad_norm": 5.423103077717428e-10,
      "learning_rate": 0.000104775,
      "loss": 0.0,
      "step": 79100
    },
    {
      "epoch": 7.916041979010495,
      "grad_norm": 5.439438344190251e-10,
      "learning_rate": 0.00010427500000000001,
      "loss": 0.0,
      "step": 79200
    },
    {
      "epoch": 7.926036981509245,
      "grad_norm": 5.439055317246755e-10,
      "learning_rate": 0.000103775,
      "loss": 0.0,
      "step": 79300
    },
    {
      "epoch": 7.936031984007996,
      "grad_norm": 5.538954295225551e-10,
      "learning_rate": 0.000103275,
      "loss": 0.0,
      "step": 79400
    },
    {
      "epoch": 7.946026986506746,
      "grad_norm": 5.443522854697846e-10,
      "learning_rate": 0.000102775,
      "loss": 0.0,
      "step": 79500
    },
    {
      "epoch": 7.956021989005498,
      "grad_norm": 5.472584052590435e-10,
      "learning_rate": 0.000102275,
      "loss": 0.0,
      "step": 79600
    },
    {
      "epoch": 7.966016991504248,
      "grad_norm": 5.422863269544109e-10,
      "learning_rate": 0.00010177500000000001,
      "loss": 0.0,
      "step": 79700
    },
    {
      "epoch": 7.976011994002999,
      "grad_norm": 5.431052829685257e-10,
      "learning_rate": 0.00010127500000000001,
      "loss": 0.0,
      "step": 79800
    },
    {
      "epoch": 7.986006996501749,
      "grad_norm": 5.524091184483382e-10,
      "learning_rate": 0.00010077500000000001,
      "loss": 0.0,
      "step": 79900
    },
    {
      "epoch": 7.9960019990005,
      "grad_norm": 5.30641530716025e-10,
      "learning_rate": 0.00010027500000000001,
      "loss": 0.0,
      "step": 80000
    },
    {
      "epoch": 8.005997001499251,
      "grad_norm": 5.424565796552372e-10,
      "learning_rate": 9.9775e-05,
      "loss": 0.0,
      "step": 80100
    },
    {
      "epoch": 8.015992003998,
      "grad_norm": 5.378991141391509e-10,
      "learning_rate": 9.9275e-05,
      "loss": 0.0,
      "step": 80200
    },
    {
      "epoch": 8.025987006496752,
      "grad_norm": 5.338962050238649e-10,
      "learning_rate": 9.8775e-05,
      "loss": 0.0,
      "step": 80300
    },
    {
      "epoch": 8.035982008995502,
      "grad_norm": 5.354050536254817e-10,
      "learning_rate": 9.8275e-05,
      "loss": 0.0,
      "step": 80400
    },
    {
      "epoch": 8.045977011494253,
      "grad_norm": 5.354962029358035e-10,
      "learning_rate": 9.7775e-05,
      "loss": 0.0,
      "step": 80500
    },
    {
      "epoch": 8.055972013993003,
      "grad_norm": 5.40863631659505e-10,
      "learning_rate": 9.7275e-05,
      "loss": 0.0,
      "step": 80600
    },
    {
      "epoch": 8.065967016491754,
      "grad_norm": 5.433988814473878e-10,
      "learning_rate": 9.677500000000001e-05,
      "loss": 0.0,
      "step": 80700
    },
    {
      "epoch": 8.075962018990504,
      "grad_norm": 5.351730170133351e-10,
      "learning_rate": 9.6275e-05,
      "loss": 0.0,
      "step": 80800
    },
    {
      "epoch": 8.085957021489255,
      "grad_norm": 5.371634803630343e-10,
      "learning_rate": 9.5775e-05,
      "loss": 0.0,
      "step": 80900
    },
    {
      "epoch": 8.095952023988007,
      "grad_norm": 5.376006306789805e-10,
      "learning_rate": 9.5275e-05,
      "loss": 0.0,
      "step": 81000
    },
    {
      "epoch": 8.105947026486756,
      "grad_norm": 5.419015791652271e-10,
      "learning_rate": 9.4775e-05,
      "loss": 0.0,
      "step": 81100
    },
    {
      "epoch": 8.115942028985508,
      "grad_norm": 5.437300609756335e-10,
      "learning_rate": 9.4275e-05,
      "loss": 0.0,
      "step": 81200
    },
    {
      "epoch": 8.125937031484257,
      "grad_norm": 5.403206770893121e-10,
      "learning_rate": 9.3775e-05,
      "loss": 0.0,
      "step": 81300
    },
    {
      "epoch": 8.135932033983009,
      "grad_norm": 5.455429996636951e-10,
      "learning_rate": 9.3275e-05,
      "loss": 0.0,
      "step": 81400
    },
    {
      "epoch": 8.145927036481758,
      "grad_norm": 5.440488060060034e-10,
      "learning_rate": 9.277499999999999e-05,
      "loss": 0.0,
      "step": 81500
    },
    {
      "epoch": 8.15592203898051,
      "grad_norm": 5.454882101574299e-10,
      "learning_rate": 9.227499999999999e-05,
      "loss": 0.0,
      "step": 81600
    },
    {
      "epoch": 8.165917041479261,
      "grad_norm": 5.533239422206293e-10,
      "learning_rate": 9.1775e-05,
      "loss": 0.0,
      "step": 81700
    },
    {
      "epoch": 8.17591204397801,
      "grad_norm": 5.400793701149098e-10,
      "learning_rate": 9.1275e-05,
      "loss": 0.0,
      "step": 81800
    },
    {
      "epoch": 8.185907046476762,
      "grad_norm": 5.472580721921361e-10,
      "learning_rate": 9.0775e-05,
      "loss": 0.0,
      "step": 81900
    },
    {
      "epoch": 8.195902048975512,
      "grad_norm": 5.514816936447176e-10,
      "learning_rate": 9.0275e-05,
      "loss": 0.0,
      "step": 82000
    },
    {
      "epoch": 8.205897051474263,
      "grad_norm": 5.286295290396481e-10,
      "learning_rate": 8.9775e-05,
      "loss": 0.0,
      "step": 82100
    },
    {
      "epoch": 8.215892053973013,
      "grad_norm": 5.433999361592612e-10,
      "learning_rate": 8.928e-05,
      "loss": 0.0,
      "step": 82200
    },
    {
      "epoch": 8.225887056471764,
      "grad_norm": 5.683671311373928e-10,
      "learning_rate": 8.878e-05,
      "loss": 0.0,
      "step": 82300
    },
    {
      "epoch": 8.235882058970514,
      "grad_norm": 6.045284828282149e-10,
      "learning_rate": 8.828e-05,
      "loss": 0.0,
      "step": 82400
    },
    {
      "epoch": 8.245877061469265,
      "grad_norm": 5.510026324095918e-10,
      "learning_rate": 8.778e-05,
      "loss": 0.0,
      "step": 82500
    },
    {
      "epoch": 8.255872063968017,
      "grad_norm": 5.509082079413474e-10,
      "learning_rate": 8.728e-05,
      "loss": 0.0,
      "step": 82600
    },
    {
      "epoch": 8.265867066466766,
      "grad_norm": 5.256041712975446e-10,
      "learning_rate": 8.677999999999999e-05,
      "loss": 0.0,
      "step": 82700
    },
    {
      "epoch": 8.275862068965518,
      "grad_norm": 5.524137258738904e-10,
      "learning_rate": 8.628e-05,
      "loss": 0.0,
      "step": 82800
    },
    {
      "epoch": 8.285857071464267,
      "grad_norm": 5.274043979319742e-10,
      "learning_rate": 8.578e-05,
      "loss": 0.0,
      "step": 82900
    },
    {
      "epoch": 8.295852073963019,
      "grad_norm": 5.431076144368774e-10,
      "learning_rate": 8.528500000000001e-05,
      "loss": 0.0,
      "step": 83000
    },
    {
      "epoch": 8.305847076461768,
      "grad_norm": 5.496340049759851e-10,
      "learning_rate": 8.4785e-05,
      "loss": 0.0,
      "step": 83100
    },
    {
      "epoch": 8.31584207896052,
      "grad_norm": 5.403868463815797e-10,
      "learning_rate": 8.4285e-05,
      "loss": 0.0,
      "step": 83200
    },
    {
      "epoch": 8.32583708145927,
      "grad_norm": 5.429998117811863e-10,
      "learning_rate": 8.3785e-05,
      "loss": 0.0,
      "step": 83300
    },
    {
      "epoch": 8.335832083958021,
      "grad_norm": 5.341912467926591e-10,
      "learning_rate": 8.3285e-05,
      "loss": 0.0,
      "step": 83400
    },
    {
      "epoch": 8.345827086456772,
      "grad_norm": 5.461758822988827e-10,
      "learning_rate": 8.2785e-05,
      "loss": 0.0,
      "step": 83500
    },
    {
      "epoch": 8.355822088955522,
      "grad_norm": 5.357468357836126e-10,
      "learning_rate": 8.2285e-05,
      "loss": 0.0,
      "step": 83600
    },
    {
      "epoch": 8.365817091454273,
      "grad_norm": 5.386016077579825e-10,
      "learning_rate": 8.1785e-05,
      "loss": 0.0,
      "step": 83700
    },
    {
      "epoch": 8.375812093953023,
      "grad_norm": 5.331481367498725e-10,
      "learning_rate": 8.128499999999999e-05,
      "loss": 0.0,
      "step": 83800
    },
    {
      "epoch": 8.385807096451774,
      "grad_norm": 5.48863676730349e-10,
      "learning_rate": 8.078499999999999e-05,
      "loss": 0.0,
      "step": 83900
    },
    {
      "epoch": 8.395802098950524,
      "grad_norm": 5.295251459536132e-10,
      "learning_rate": 8.0285e-05,
      "loss": 0.0,
      "step": 84000
    },
    {
      "epoch": 8.405797101449275,
      "grad_norm": 5.379073297895332e-10,
      "learning_rate": 7.9785e-05,
      "loss": 0.0,
      "step": 84100
    },
    {
      "epoch": 8.415792103948027,
      "grad_norm": 5.272801639755187e-10,
      "learning_rate": 7.9285e-05,
      "loss": 0.0,
      "step": 84200
    },
    {
      "epoch": 8.425787106446776,
      "grad_norm": 5.372406408632457e-10,
      "learning_rate": 7.8785e-05,
      "loss": 0.0,
      "step": 84300
    },
    {
      "epoch": 8.435782108945528,
      "grad_norm": 5.415284332066506e-10,
      "learning_rate": 7.8285e-05,
      "loss": 0.0,
      "step": 84400
    },
    {
      "epoch": 8.445777111444277,
      "grad_norm": 5.461004981555106e-10,
      "learning_rate": 7.778500000000002e-05,
      "loss": 0.0,
      "step": 84500
    },
    {
      "epoch": 8.455772113943029,
      "grad_norm": 5.398332891815016e-10,
      "learning_rate": 7.7285e-05,
      "loss": 0.0,
      "step": 84600
    },
    {
      "epoch": 8.465767116441778,
      "grad_norm": 5.397542413021483e-10,
      "learning_rate": 7.6785e-05,
      "loss": 0.0,
      "step": 84700
    },
    {
      "epoch": 8.47576211894053,
      "grad_norm": 5.36115873916998e-10,
      "learning_rate": 7.6285e-05,
      "loss": 0.0,
      "step": 84800
    },
    {
      "epoch": 8.48575712143928,
      "grad_norm": 5.31231780787067e-10,
      "learning_rate": 7.578500000000001e-05,
      "loss": 0.0,
      "step": 84900
    },
    {
      "epoch": 8.495752123938031,
      "grad_norm": 5.498228539124739e-10,
      "learning_rate": 7.528500000000001e-05,
      "loss": 0.0,
      "step": 85000
    },
    {
      "epoch": 8.505747126436782,
      "grad_norm": 5.404618974580444e-10,
      "learning_rate": 7.478500000000001e-05,
      "loss": 0.0,
      "step": 85100
    },
    {
      "epoch": 8.515742128935532,
      "grad_norm": 5.378405498746019e-10,
      "learning_rate": 7.428500000000001e-05,
      "loss": 0.0,
      "step": 85200
    },
    {
      "epoch": 8.525737131434283,
      "grad_norm": 5.413839931911468e-10,
      "learning_rate": 7.3785e-05,
      "loss": 0.0,
      "step": 85300
    },
    {
      "epoch": 8.535732133933033,
      "grad_norm": 5.420011106593847e-10,
      "learning_rate": 7.3285e-05,
      "loss": 0.0,
      "step": 85400
    },
    {
      "epoch": 8.545727136431784,
      "grad_norm": 5.349872211901641e-10,
      "learning_rate": 7.2785e-05,
      "loss": 0.0,
      "step": 85500
    },
    {
      "epoch": 8.555722138930534,
      "grad_norm": 5.399448665954765e-10,
      "learning_rate": 7.2285e-05,
      "loss": 0.0,
      "step": 85600
    },
    {
      "epoch": 8.565717141429285,
      "grad_norm": 5.43216027715232e-10,
      "learning_rate": 7.1785e-05,
      "loss": 0.0,
      "step": 85700
    },
    {
      "epoch": 8.575712143928037,
      "grad_norm": 5.41301226064661e-10,
      "learning_rate": 7.1285e-05,
      "loss": 0.0,
      "step": 85800
    },
    {
      "epoch": 8.585707146426786,
      "grad_norm": 5.487618137678396e-10,
      "learning_rate": 7.078500000000001e-05,
      "loss": 0.0,
      "step": 85900
    },
    {
      "epoch": 8.595702148925538,
      "grad_norm": 5.327729368787004e-10,
      "learning_rate": 7.0285e-05,
      "loss": 0.0,
      "step": 86000
    },
    {
      "epoch": 8.605697151424287,
      "grad_norm": 5.440618511265427e-10,
      "learning_rate": 6.9785e-05,
      "loss": 0.0,
      "step": 86100
    },
    {
      "epoch": 8.615692153923039,
      "grad_norm": 5.357899124369681e-10,
      "learning_rate": 6.9285e-05,
      "loss": 0.0,
      "step": 86200
    },
    {
      "epoch": 8.625687156421789,
      "grad_norm": 5.460307761495642e-10,
      "learning_rate": 6.8785e-05,
      "loss": 0.0,
      "step": 86300
    },
    {
      "epoch": 8.63568215892054,
      "grad_norm": 5.402812086607867e-10,
      "learning_rate": 6.8285e-05,
      "loss": 0.0,
      "step": 86400
    },
    {
      "epoch": 8.64567716141929,
      "grad_norm": 5.428147376029813e-10,
      "learning_rate": 6.7785e-05,
      "loss": 0.0,
      "step": 86500
    },
    {
      "epoch": 8.655672163918041,
      "grad_norm": 5.479837139610311e-10,
      "learning_rate": 6.7285e-05,
      "loss": 0.0,
      "step": 86600
    },
    {
      "epoch": 8.665667166416792,
      "grad_norm": 5.428080762648335e-10,
      "learning_rate": 6.6785e-05,
      "loss": 0.0,
      "step": 86700
    },
    {
      "epoch": 8.675662168915542,
      "grad_norm": 5.50367529328355e-10,
      "learning_rate": 6.628499999999999e-05,
      "loss": 0.0,
      "step": 86800
    },
    {
      "epoch": 8.685657171414293,
      "grad_norm": 5.383172241302248e-10,
      "learning_rate": 6.5785e-05,
      "loss": 0.0,
      "step": 86900
    },
    {
      "epoch": 8.695652173913043,
      "grad_norm": 5.364232391613655e-10,
      "learning_rate": 6.5285e-05,
      "loss": 0.0,
      "step": 87000
    },
    {
      "epoch": 8.705647176411794,
      "grad_norm": 5.496793020753898e-10,
      "learning_rate": 6.4785e-05,
      "loss": 0.0,
      "step": 87100
    },
    {
      "epoch": 8.715642178910544,
      "grad_norm": 5.452264195682233e-10,
      "learning_rate": 6.4285e-05,
      "loss": 0.0,
      "step": 87200
    },
    {
      "epoch": 8.725637181409295,
      "grad_norm": 5.372164935124601e-10,
      "learning_rate": 6.3785e-05,
      "loss": 0.0,
      "step": 87300
    },
    {
      "epoch": 8.735632183908045,
      "grad_norm": 5.375017653186376e-10,
      "learning_rate": 6.3285e-05,
      "loss": 0.0,
      "step": 87400
    },
    {
      "epoch": 8.745627186406796,
      "grad_norm": 5.418629434039701e-10,
      "learning_rate": 6.278499999999999e-05,
      "loss": 0.0,
      "step": 87500
    },
    {
      "epoch": 8.755622188905548,
      "grad_norm": 5.29633115142758e-10,
      "learning_rate": 6.2285e-05,
      "loss": 0.0,
      "step": 87600
    },
    {
      "epoch": 8.765617191404298,
      "grad_norm": 5.408010705920674e-10,
      "learning_rate": 6.1785e-05,
      "loss": 0.0,
      "step": 87700
    },
    {
      "epoch": 8.775612193903049,
      "grad_norm": 5.234879196791553e-10,
      "learning_rate": 6.128500000000001e-05,
      "loss": 0.0,
      "step": 87800
    },
    {
      "epoch": 8.785607196401799,
      "grad_norm": 5.421023074880793e-10,
      "learning_rate": 6.0785e-05,
      "loss": 0.0,
      "step": 87900
    },
    {
      "epoch": 8.79560219890055,
      "grad_norm": 5.410861758647911e-10,
      "learning_rate": 6.0284999999999996e-05,
      "loss": 0.0,
      "step": 88000
    },
    {
      "epoch": 8.8055972013993,
      "grad_norm": 5.393726021374334e-10,
      "learning_rate": 5.9785e-05,
      "loss": 0.0,
      "step": 88100
    },
    {
      "epoch": 8.815592203898051,
      "grad_norm": 5.333990471534378e-10,
      "learning_rate": 5.9285e-05,
      "loss": 0.0,
      "step": 88200
    },
    {
      "epoch": 8.825587206396802,
      "grad_norm": 5.31775457002226e-10,
      "learning_rate": 5.8785e-05,
      "loss": 0.0,
      "step": 88300
    },
    {
      "epoch": 8.835582208895552,
      "grad_norm": 5.385685231118487e-10,
      "learning_rate": 5.8284999999999995e-05,
      "loss": 0.0,
      "step": 88400
    },
    {
      "epoch": 8.845577211394303,
      "grad_norm": 5.484538934119598e-10,
      "learning_rate": 5.7785e-05,
      "loss": 0.0,
      "step": 88500
    },
    {
      "epoch": 8.855572213893053,
      "grad_norm": 5.313616213697969e-10,
      "learning_rate": 5.7285000000000005e-05,
      "loss": 0.0,
      "step": 88600
    },
    {
      "epoch": 8.865567216391804,
      "grad_norm": 5.386264767537341e-10,
      "learning_rate": 5.6785000000000006e-05,
      "loss": 0.0,
      "step": 88700
    },
    {
      "epoch": 8.875562218890554,
      "grad_norm": 5.508704603585102e-10,
      "learning_rate": 5.6285e-05,
      "loss": 0.0,
      "step": 88800
    },
    {
      "epoch": 8.885557221389305,
      "grad_norm": 5.280151316178205e-10,
      "learning_rate": 5.5785e-05,
      "loss": 0.0,
      "step": 88900
    },
    {
      "epoch": 8.895552223888057,
      "grad_norm": 5.495536803401535e-10,
      "learning_rate": 5.529e-05,
      "loss": 0.0,
      "step": 89000
    },
    {
      "epoch": 8.905547226386807,
      "grad_norm": 5.374660716483959e-10,
      "learning_rate": 5.479e-05,
      "loss": 0.0,
      "step": 89100
    },
    {
      "epoch": 8.915542228885558,
      "grad_norm": 6.283802922446569e-10,
      "learning_rate": 5.429e-05,
      "loss": 0.0,
      "step": 89200
    },
    {
      "epoch": 8.925537231384308,
      "grad_norm": 5.393617774629433e-10,
      "learning_rate": 5.3795e-05,
      "loss": 0.0,
      "step": 89300
    },
    {
      "epoch": 8.935532233883059,
      "grad_norm": 5.274765624285749e-10,
      "learning_rate": 5.3295000000000004e-05,
      "loss": 0.0,
      "step": 89400
    },
    {
      "epoch": 8.945527236381809,
      "grad_norm": 5.344136799756427e-10,
      "learning_rate": 5.2795000000000005e-05,
      "loss": 0.0,
      "step": 89500
    },
    {
      "epoch": 8.95552223888056,
      "grad_norm": 5.388094415081923e-10,
      "learning_rate": 5.2295e-05,
      "loss": 0.0,
      "step": 89600
    },
    {
      "epoch": 8.96551724137931,
      "grad_norm": 5.378261169752818e-10,
      "learning_rate": 5.1795e-05,
      "loss": 0.0,
      "step": 89700
    },
    {
      "epoch": 8.975512243878061,
      "grad_norm": 5.370437428098285e-10,
      "learning_rate": 5.1295e-05,
      "loss": 0.0,
      "step": 89800
    },
    {
      "epoch": 8.985507246376812,
      "grad_norm": 5.266684866001015e-10,
      "learning_rate": 5.0795000000000004e-05,
      "loss": 0.0,
      "step": 89900
    },
    {
      "epoch": 8.995502248875562,
      "grad_norm": 5.334638286669247e-10,
      "learning_rate": 5.0295e-05,
      "loss": 0.0,
      "step": 90000
    },
    {
      "epoch": 9.005497251374313,
      "grad_norm": 5.45988254607721e-10,
      "learning_rate": 4.9795e-05,
      "loss": 0.0,
      "step": 90100
    },
    {
      "epoch": 9.015492253873063,
      "grad_norm": 5.377349676649601e-10,
      "learning_rate": 4.9295e-05,
      "loss": 0.0,
      "step": 90200
    },
    {
      "epoch": 9.025487256371814,
      "grad_norm": 5.393263058373066e-10,
      "learning_rate": 4.8794999999999996e-05,
      "loss": 0.0,
      "step": 90300
    },
    {
      "epoch": 9.035482258870564,
      "grad_norm": 5.390499713264774e-10,
      "learning_rate": 4.83e-05,
      "loss": 0.0,
      "step": 90400
    },
    {
      "epoch": 9.045477261369316,
      "grad_norm": 5.29746413402421e-10,
      "learning_rate": 4.78e-05,
      "loss": 0.0,
      "step": 90500
    },
    {
      "epoch": 9.055472263868065,
      "grad_norm": 5.452964191299259e-10,
      "learning_rate": 4.7300000000000005e-05,
      "loss": 0.0,
      "step": 90600
    },
    {
      "epoch": 9.065467266366817,
      "grad_norm": 5.480104148247733e-10,
      "learning_rate": 4.68e-05,
      "loss": 0.0,
      "step": 90700
    },
    {
      "epoch": 9.075462268865568,
      "grad_norm": 5.465583541308661e-10,
      "learning_rate": 4.63e-05,
      "loss": 0.0,
      "step": 90800
    },
    {
      "epoch": 9.085457271364318,
      "grad_norm": 5.363300359384482e-10,
      "learning_rate": 4.58e-05,
      "loss": 0.0,
      "step": 90900
    },
    {
      "epoch": 9.095452273863069,
      "grad_norm": 5.406344816272224e-10,
      "learning_rate": 4.53e-05,
      "loss": 0.0,
      "step": 91000
    },
    {
      "epoch": 9.105447276361819,
      "grad_norm": 5.418146487023989e-10,
      "learning_rate": 4.48e-05,
      "loss": 0.0,
      "step": 91100
    },
    {
      "epoch": 9.11544227886057,
      "grad_norm": 5.390021762252672e-10,
      "learning_rate": 4.43e-05,
      "loss": 0.0,
      "step": 91200
    },
    {
      "epoch": 9.12543728135932,
      "grad_norm": 5.359703236784696e-10,
      "learning_rate": 4.38e-05,
      "loss": 0.0,
      "step": 91300
    },
    {
      "epoch": 9.135432283858071,
      "grad_norm": 5.250285761704276e-10,
      "learning_rate": 4.33e-05,
      "loss": 0.0,
      "step": 91400
    },
    {
      "epoch": 9.145427286356822,
      "grad_norm": 5.370939248905415e-10,
      "learning_rate": 4.2805e-05,
      "loss": 0.0,
      "step": 91500
    },
    {
      "epoch": 9.155422288855572,
      "grad_norm": 5.305901273899849e-10,
      "learning_rate": 4.2305e-05,
      "loss": 0.0,
      "step": 91600
    },
    {
      "epoch": 9.165417291354323,
      "grad_norm": 5.334530595035858e-10,
      "learning_rate": 4.1805000000000004e-05,
      "loss": 0.0,
      "step": 91700
    },
    {
      "epoch": 9.175412293853073,
      "grad_norm": 5.276409309473706e-10,
      "learning_rate": 4.1305000000000005e-05,
      "loss": 0.0,
      "step": 91800
    },
    {
      "epoch": 9.185407296351825,
      "grad_norm": 5.326789009885147e-10,
      "learning_rate": 4.0805e-05,
      "loss": 0.0,
      "step": 91900
    },
    {
      "epoch": 9.195402298850574,
      "grad_norm": 5.473652087140124e-10,
      "learning_rate": 4.0305e-05,
      "loss": 0.0,
      "step": 92000
    },
    {
      "epoch": 9.205397301349326,
      "grad_norm": 5.379655054760235e-10,
      "learning_rate": 3.9805e-05,
      "loss": 0.0,
      "step": 92100
    },
    {
      "epoch": 9.215392303848075,
      "grad_norm": 5.398459457239824e-10,
      "learning_rate": 3.9305e-05,
      "loss": 0.0,
      "step": 92200
    },
    {
      "epoch": 9.225387306346827,
      "grad_norm": 5.365883293251272e-10,
      "learning_rate": 3.8805e-05,
      "loss": 0.0,
      "step": 92300
    },
    {
      "epoch": 9.235382308845578,
      "grad_norm": 5.357224663882221e-10,
      "learning_rate": 3.8305e-05,
      "loss": 0.0,
      "step": 92400
    },
    {
      "epoch": 9.245377311344328,
      "grad_norm": 5.497815536159578e-10,
      "learning_rate": 3.7805e-05,
      "loss": 0.0,
      "step": 92500
    },
    {
      "epoch": 9.255372313843079,
      "grad_norm": 5.343600006924021e-10,
      "learning_rate": 3.7304999999999996e-05,
      "loss": 0.0,
      "step": 92600
    },
    {
      "epoch": 9.265367316341829,
      "grad_norm": 5.274066183780235e-10,
      "learning_rate": 3.6805e-05,
      "loss": 0.0,
      "step": 92700
    },
    {
      "epoch": 9.27536231884058,
      "grad_norm": 5.434468985932028e-10,
      "learning_rate": 3.6305e-05,
      "loss": 0.0,
      "step": 92800
    },
    {
      "epoch": 9.28535732133933,
      "grad_norm": 5.485962240037168e-10,
      "learning_rate": 3.5805e-05,
      "loss": 0.0,
      "step": 92900
    },
    {
      "epoch": 9.295352323838081,
      "grad_norm": 5.380684786615575e-10,
      "learning_rate": 3.5305e-05,
      "loss": 0.0,
      "step": 93000
    },
    {
      "epoch": 9.305347326336832,
      "grad_norm": 5.316572737612546e-10,
      "learning_rate": 3.4805e-05,
      "loss": 0.0,
      "step": 93100
    },
    {
      "epoch": 9.315342328835582,
      "grad_norm": 5.370299760443231e-10,
      "learning_rate": 3.4305000000000004e-05,
      "loss": 0.0,
      "step": 93200
    },
    {
      "epoch": 9.325337331334334,
      "grad_norm": 5.227291377529752e-10,
      "learning_rate": 3.3805e-05,
      "loss": 0.0,
      "step": 93300
    },
    {
      "epoch": 9.335332333833083,
      "grad_norm": 5.279319759132761e-10,
      "learning_rate": 3.3305e-05,
      "loss": 0.0,
      "step": 93400
    },
    {
      "epoch": 9.345327336331835,
      "grad_norm": 5.506540778910107e-10,
      "learning_rate": 3.2805e-05,
      "loss": 0.0,
      "step": 93500
    },
    {
      "epoch": 9.355322338830584,
      "grad_norm": 5.396633695475828e-10,
      "learning_rate": 3.2305e-05,
      "loss": 0.0,
      "step": 93600
    },
    {
      "epoch": 9.365317341329336,
      "grad_norm": 5.379391376791887e-10,
      "learning_rate": 3.1805e-05,
      "loss": 0.0,
      "step": 93700
    },
    {
      "epoch": 9.375312343828085,
      "grad_norm": 5.486539556009973e-10,
      "learning_rate": 3.1305e-05,
      "loss": 0.0,
      "step": 93800
    },
    {
      "epoch": 9.385307346326837,
      "grad_norm": 5.584502860145335e-10,
      "learning_rate": 3.0805e-05,
      "loss": 0.0,
      "step": 93900
    },
    {
      "epoch": 9.395302348825588,
      "grad_norm": 5.339911846036216e-10,
      "learning_rate": 3.0305e-05,
      "loss": 0.0,
      "step": 94000
    },
    {
      "epoch": 9.405297351324338,
      "grad_norm": 5.225330723668264e-10,
      "learning_rate": 2.9805000000000003e-05,
      "loss": 0.0,
      "step": 94100
    },
    {
      "epoch": 9.415292353823089,
      "grad_norm": 5.46073464224861e-10,
      "learning_rate": 2.9305e-05,
      "loss": 0.0,
      "step": 94200
    },
    {
      "epoch": 9.425287356321839,
      "grad_norm": 5.330357266686292e-10,
      "learning_rate": 2.8805000000000003e-05,
      "loss": 0.0,
      "step": 94300
    },
    {
      "epoch": 9.43528235882059,
      "grad_norm": 5.363924304724321e-10,
      "learning_rate": 2.8305e-05,
      "loss": 0.0,
      "step": 94400
    },
    {
      "epoch": 9.44527736131934,
      "grad_norm": 5.356584620308524e-10,
      "learning_rate": 2.7805e-05,
      "loss": 0.0,
      "step": 94500
    },
    {
      "epoch": 9.455272363818091,
      "grad_norm": 5.399965474772728e-10,
      "learning_rate": 2.7305e-05,
      "loss": 0.0,
      "step": 94600
    },
    {
      "epoch": 9.46526736631684,
      "grad_norm": 5.25450183364029e-10,
      "learning_rate": 2.6805e-05,
      "loss": 0.0,
      "step": 94700
    },
    {
      "epoch": 9.475262368815592,
      "grad_norm": 5.336568409397557e-10,
      "learning_rate": 2.6305e-05,
      "loss": 0.0,
      "step": 94800
    },
    {
      "epoch": 9.485257371314344,
      "grad_norm": 5.338053332692994e-10,
      "learning_rate": 2.5805e-05,
      "loss": 0.0,
      "step": 94900
    },
    {
      "epoch": 9.495252373813093,
      "grad_norm": 5.246906242817317e-10,
      "learning_rate": 2.5305000000000003e-05,
      "loss": 0.0,
      "step": 95000
    },
    {
      "epoch": 9.505247376311845,
      "grad_norm": 5.470322528289273e-10,
      "learning_rate": 2.4805e-05,
      "loss": 0.0,
      "step": 95100
    },
    {
      "epoch": 9.515242378810594,
      "grad_norm": 5.324178320442741e-10,
      "learning_rate": 2.4305000000000002e-05,
      "loss": 0.0,
      "step": 95200
    },
    {
      "epoch": 9.525237381309346,
      "grad_norm": 5.32004940101416e-10,
      "learning_rate": 2.3805e-05,
      "loss": 0.0,
      "step": 95300
    },
    {
      "epoch": 9.535232383808095,
      "grad_norm": 5.473227981944717e-10,
      "learning_rate": 2.3305e-05,
      "loss": 0.0,
      "step": 95400
    },
    {
      "epoch": 9.545227386306847,
      "grad_norm": 5.344186204681023e-10,
      "learning_rate": 2.2805e-05,
      "loss": 0.0,
      "step": 95500
    },
    {
      "epoch": 9.555222388805596,
      "grad_norm": 5.439408923280098e-10,
      "learning_rate": 2.2304999999999997e-05,
      "loss": 0.0,
      "step": 95600
    },
    {
      "epoch": 9.565217391304348,
      "grad_norm": 5.363648414302702e-10,
      "learning_rate": 2.1805000000000002e-05,
      "loss": 0.0,
      "step": 95700
    },
    {
      "epoch": 9.575212393803099,
      "grad_norm": 5.369690248002712e-10,
      "learning_rate": 2.1305e-05,
      "loss": 0.0,
      "step": 95800
    },
    {
      "epoch": 9.585207396301849,
      "grad_norm": 5.291962978937192e-10,
      "learning_rate": 2.0805e-05,
      "loss": 0.0,
      "step": 95900
    },
    {
      "epoch": 9.5952023988006,
      "grad_norm": 5.554282034303526e-10,
      "learning_rate": 2.0305e-05,
      "loss": 0.0,
      "step": 96000
    },
    {
      "epoch": 9.60519740129935,
      "grad_norm": 5.566296867876019e-10,
      "learning_rate": 1.9810000000000002e-05,
      "loss": 0.0,
      "step": 96100
    },
    {
      "epoch": 9.615192403798101,
      "grad_norm": 5.517841739077767e-10,
      "learning_rate": 1.931e-05,
      "loss": 0.0,
      "step": 96200
    },
    {
      "epoch": 9.62518740629685,
      "grad_norm": 5.438838823756953e-10,
      "learning_rate": 1.8815e-05,
      "loss": 0.0,
      "step": 96300
    },
    {
      "epoch": 9.635182408795602,
      "grad_norm": 5.315400342098542e-10,
      "learning_rate": 1.8315000000000003e-05,
      "loss": 0.0,
      "step": 96400
    },
    {
      "epoch": 9.645177411294354,
      "grad_norm": 5.342206121916604e-10,
      "learning_rate": 1.7815e-05,
      "loss": 0.0,
      "step": 96500
    },
    {
      "epoch": 9.655172413793103,
      "grad_norm": 5.351827869759518e-10,
      "learning_rate": 1.7315e-05,
      "loss": 0.0,
      "step": 96600
    },
    {
      "epoch": 9.665167416291855,
      "grad_norm": 5.25615329038942e-10,
      "learning_rate": 1.6815e-05,
      "loss": 0.0,
      "step": 96700
    },
    {
      "epoch": 9.675162418790604,
      "grad_norm": 5.493591692662392e-10,
      "learning_rate": 1.6315e-05,
      "loss": 0.0,
      "step": 96800
    },
    {
      "epoch": 9.685157421289356,
      "grad_norm": 5.323048113403672e-10,
      "learning_rate": 1.5815e-05,
      "loss": 0.0,
      "step": 96900
    },
    {
      "epoch": 9.695152423788105,
      "grad_norm": 5.449835027704353e-10,
      "learning_rate": 1.5315e-05,
      "loss": 0.0,
      "step": 97000
    },
    {
      "epoch": 9.705147426286857,
      "grad_norm": 5.369272804145453e-10,
      "learning_rate": 1.4815e-05,
      "loss": 0.0,
      "step": 97100
    },
    {
      "epoch": 9.715142428785608,
      "grad_norm": 5.375357936543423e-10,
      "learning_rate": 1.4315e-05,
      "loss": 0.0,
      "step": 97200
    },
    {
      "epoch": 9.725137431284358,
      "grad_norm": 5.349296561263372e-10,
      "learning_rate": 1.3814999999999999e-05,
      "loss": 0.0,
      "step": 97300
    },
    {
      "epoch": 9.735132433783109,
      "grad_norm": 5.382976842049914e-10,
      "learning_rate": 1.3315e-05,
      "loss": 0.0,
      "step": 97400
    },
    {
      "epoch": 9.745127436281859,
      "grad_norm": 5.327128738130682e-10,
      "learning_rate": 1.2815e-05,
      "loss": 0.0,
      "step": 97500
    },
    {
      "epoch": 9.75512243878061,
      "grad_norm": 5.435756289529081e-10,
      "learning_rate": 1.2315e-05,
      "loss": 0.0,
      "step": 97600
    },
    {
      "epoch": 9.76511744127936,
      "grad_norm": 5.422876592220405e-10,
      "learning_rate": 1.1815000000000001e-05,
      "loss": 0.0,
      "step": 97700
    },
    {
      "epoch": 9.775112443778111,
      "grad_norm": 5.479093845295324e-10,
      "learning_rate": 1.1315000000000001e-05,
      "loss": 0.0,
      "step": 97800
    },
    {
      "epoch": 9.78510744627686,
      "grad_norm": 5.549622983380686e-10,
      "learning_rate": 1.0815e-05,
      "loss": 0.0,
      "step": 97900
    },
    {
      "epoch": 9.795102448775612,
      "grad_norm": 5.386333046253355e-10,
      "learning_rate": 1.0315e-05,
      "loss": 0.0,
      "step": 98000
    },
    {
      "epoch": 9.805097451274364,
      "grad_norm": 5.368770983338322e-10,
      "learning_rate": 9.815000000000002e-06,
      "loss": 0.0,
      "step": 98100
    },
    {
      "epoch": 9.815092453773113,
      "grad_norm": 5.380030865254071e-10,
      "learning_rate": 9.315e-06,
      "loss": 0.0,
      "step": 98200
    },
    {
      "epoch": 9.825087456271865,
      "grad_norm": 5.476452069608229e-10,
      "learning_rate": 8.815e-06,
      "loss": 0.0,
      "step": 98300
    },
    {
      "epoch": 9.835082458770614,
      "grad_norm": 5.334602759532459e-10,
      "learning_rate": 8.315e-06,
      "loss": 0.0,
      "step": 98400
    },
    {
      "epoch": 9.845077461269366,
      "grad_norm": 5.374056755158563e-10,
      "learning_rate": 7.815e-06,
      "loss": 0.0,
      "step": 98500
    },
    {
      "epoch": 9.855072463768115,
      "grad_norm": 5.354453547212756e-10,
      "learning_rate": 7.315e-06,
      "loss": 0.0,
      "step": 98600
    },
    {
      "epoch": 9.865067466266867,
      "grad_norm": 5.791443435931853e-10,
      "learning_rate": 6.815e-06,
      "loss": 0.0,
      "step": 98700
    },
    {
      "epoch": 9.875062468765616,
      "grad_norm": 5.368354649704088e-10,
      "learning_rate": 6.3150000000000005e-06,
      "loss": 0.0,
      "step": 98800
    },
    {
      "epoch": 9.885057471264368,
      "grad_norm": 5.191806429216683e-10,
      "learning_rate": 5.815e-06,
      "loss": 0.0,
      "step": 98900
    },
    {
      "epoch": 9.89505247376312,
      "grad_norm": 5.292185023542118e-10,
      "learning_rate": 5.315000000000001e-06,
      "loss": 0.0,
      "step": 99000
    },
    {
      "epoch": 9.905047476261869,
      "grad_norm": 5.257360102817188e-10,
      "learning_rate": 4.815e-06,
      "loss": 0.0,
      "step": 99100
    },
    {
      "epoch": 9.91504247876062,
      "grad_norm": 5.22069443231743e-10,
      "learning_rate": 4.315e-06,
      "loss": 0.0,
      "step": 99200
    },
    {
      "epoch": 9.92503748125937,
      "grad_norm": 5.288938176306601e-10,
      "learning_rate": 3.815e-06,
      "loss": 0.0,
      "step": 99300
    },
    {
      "epoch": 9.935032483758121,
      "grad_norm": 5.416018744597295e-10,
      "learning_rate": 3.315e-06,
      "loss": 0.0,
      "step": 99400
    },
    {
      "epoch": 9.94502748625687,
      "grad_norm": 5.405737524277754e-10,
      "learning_rate": 2.8149999999999997e-06,
      "loss": 0.0,
      "step": 99500
    },
    {
      "epoch": 9.955022488755622,
      "grad_norm": 5.369081845785217e-10,
      "learning_rate": 2.315e-06,
      "loss": 0.0,
      "step": 99600
    },
    {
      "epoch": 9.965017491254374,
      "grad_norm": 5.31923338709106e-10,
      "learning_rate": 1.815e-06,
      "loss": 0.0,
      "step": 99700
    },
    {
      "epoch": 9.975012493753123,
      "grad_norm": 5.294024107982409e-10,
      "learning_rate": 1.315e-06,
      "loss": 0.0,
      "step": 99800
    },
    {
      "epoch": 9.985007496251875,
      "grad_norm": 5.369279465483601e-10,
      "learning_rate": 8.15e-07,
      "loss": 0.0,
      "step": 99900
    },
    {
      "epoch": 9.995002498750624,
      "grad_norm": 5.341356246191253e-10,
      "learning_rate": 3.15e-07,
      "loss": 0.0,
      "step": 100000
    }
  ],
  "logging_steps": 100,
  "max_steps": 100050,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 6541855948800000.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
